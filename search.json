[
  {
    "objectID": "posts/second-post/index.html",
    "href": "posts/second-post/index.html",
    "title": "Second Post",
    "section": "",
    "text": "To learn more about Quarto websites visit https://quarto.org/docs/websites. I would like to tell my story but where should I start ? This is important for me to understand how to communicate several problems ?"
  },
  {
    "objectID": "posts/first-post/index.html",
    "href": "posts/first-post/index.html",
    "title": "First Post",
    "section": "",
    "text": "To learn more about Quarto websites visit https://quarto.org/docs/websites. I would like to tell my story but where should I start ? This is important for me to understand how to communicate several problems ?"
  },
  {
    "objectID": "xG_for_against_subplots.html#package-prerequisites",
    "href": "xG_for_against_subplots.html#package-prerequisites",
    "title": "Allsvenskan 2021",
    "section": "Package Prerequisites",
    "text": "Package Prerequisites\n\n# import required libraries\nimport os\nimport json\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib_inline\nfrom matplotlib.font_manager import FontProperties\nfrom matplotlib import image\nfrom matplotlib.offsetbox import OffsetImage, AnnotationBbox"
  },
  {
    "objectID": "xG_for_against_subplots.html#data-preparation",
    "href": "xG_for_against_subplots.html#data-preparation",
    "title": "Allsvenskan 2021",
    "section": "Data Preparation",
    "text": "Data Preparation\n\n# export required data frame\ndf = pd.read_csv(\"data/refined/merged_match_results.csv\")\n\n# find for each team xG For and xG against\nall_xg_for = pd.concat([df['home_np_xg'], df['away_np_xg']])\nall_xg_against = pd.concat([df['away_np_xg'], df['home_np_xg']])"
  },
  {
    "objectID": "xG_for_against_subplots.html#plot-extras",
    "href": "xG_for_against_subplots.html#plot-extras",
    "title": "Allsvenskan 2021",
    "section": "Plot Extras",
    "text": "Plot Extras\n\n# define a dictionary of colors for each team\nteam_color = {'Malmö FF':['skyblue', 'white'], \n              'AIK':['darkblue', 'yellow'],  \n              'Djurgården':['skyblue', 'darkblue'], \n              'IF Elfsborg':['yellow', 'black'], \n              'Hammarby':['white', 'darkgreen'],\n              'Kalmar FF':['red', '#EBCD57'], \n              'IFK Norrköping FK':['white', 'blue'], \n              'IFK Göteborg':['blue', '#EBCD57'], \n              'Mjällby AIF':['#FCDF51', 'black'],\n              'Varbergs BoIS FC':['#53B663', 'black'], \n              'IK Sirius FK':['blue', 'black'], \n              'BK Häcken':['black', '#FFF275'], \n              'Degerfors IF':['white', 'red'],\n              'Halmstad':['#6B91EB', 'black'], \n              'Örebro':['white', 'black'], \n              'Östersund':['red', 'black']}\n\n# create a list of teams, according to their ranking, to iterate over\nteam_ranks = ['Malmö FF', 'AIK', 'Djurgården', 'IF Elfsborg', 'Hammarby',\n'Kalmar FF', 'IFK Norrköping FK', 'IFK Göteborg', 'Mjällby AIF',\n'Varbergs BoIS FC', 'IK Sirius FK', 'BK Häcken', 'Degerfors IF',\n'Halmstad', 'Örebro', 'Östersund']"
  },
  {
    "objectID": "xG_for_against_subplots.html#design",
    "href": "xG_for_against_subplots.html#design",
    "title": "Allsvenskan 2021",
    "section": "Design",
    "text": "Design\n\n# list of club logo paths to iterate over \nfiles = os.listdir('images/club_logos/')\n\nfig, ax = plt.subplots(nrows = 4, ncols = 4, figsize = (18, 18), \n                            gridspec_kw={'hspace': 0.44})\n\n# figure face color equal to axis face color\nfig.set_facecolor(\"#FFF7EE\")\n\n# Font Properties:\n# (x, y) axis labels\nlabel_fps = FontProperties(family = 'Maven Pro', size = 28, weight = 'medium')\n# each plot title\nax_fps = FontProperties(family = 'Maven Pro', size = 20, weight = 'medium')\n# figure title\nfig_fps = FontProperties(family = 'Maven Pro', size = 45, weight = 'medium')\n# data source:\nds_fps = FontProperties(family = 'Maven Pro', size = 16)\n\n\nind = 0\nfor i in range(4):\n    for j in range(4):\n        \n        # grid settings\n        ax[i, j].grid(color='#62625F', ls = '-.', lw = 0.25, zorder = 0)\n\n        # face color of axis\n        ax[i, j].set_facecolor(\"#FFF7EE\")\n        \n        # plot dashed line \n        x = np.array([0, 7])\n        y = np.array([0, 7])\n        ax[i, j].plot(x, y, c = 'darkgray', ls = '--', lw = 1, zorder = 3)\n\n        # data filtering steps: \n        # 1.take a team from a list and filter data frame 'team_df'\n        team_df = df[(df['home'] == team_ranks[ind]) | (df['away'] == team_ranks[ind])]\n        \n        # 2. filter non-penalty xG for\n        team_df[team_df['home'] == team_ranks[ind]]['home_np_xg']\n        team_df[team_df['away'] == team_ranks[ind]]['away_np_xg']\n        xg_for = pd.concat([team_df[team_df['home'] == team_ranks[ind]]['home_np_xg'],\n                 team_df[team_df['away'] == team_ranks[ind]]['away_np_xg']])\n        \n        # 3. filter non-penalty xG against\n        team_df[team_df['home'] == team_ranks[ind]]['away_np_xg']\n        team_df[team_df['away'] == team_ranks[ind]]['home_np_xg']\n        xg_against = pd.concat([team_df[team_df['home'] == team_ranks[ind]]['away_np_xg'], \n                     team_df[team_df['away'] == team_ranks[ind]]['home_np_xg']])\n\n        \n        ax[i, j].scatter(all_xg_against, all_xg_for, c = 'gray', alpha = 0.3, s = 50, edgecolor = 'none', zorder = 3)\n        ax[i, j].scatter(xg_against, xg_for, s = 100, c = team_color[team_ranks[ind]][0], \n                         edgecolor = team_color[team_ranks[ind]][1], zorder = 3)\n\n        # set limit for x and y axis\n        ax[i, j].set_xlim(0, 7)\n        ax[i, j].set_ylim(0, 7)\n        ax[i, j].set_xticks(np.arange(0, 8, 1))\n        ax[i, j].set_xticks(np.arange(0, 8, 1))\n        ax[i, j].set_aspect('equal')\n        \n        # remove tick lines from both axis\n        ax[i, j].tick_params(length = 0)\n\n        # remove '0' on y-axis\n        ax[i, j].yaxis.get_major_ticks()[0].label1.set_visible(False)\n        \n        # remove top and right spines\n        ax[i, j].spines[['top', 'right']].set_visible(False)\n        \n        # spines color\n        spines_color = '#62625F'\n        ax[i, j].spines['bottom'].set_color(spines_color)\n        ax[i, j].spines['top'].set_color(spines_color) \n        ax[i, j].spines['right'].set_color(spines_color)\n        ax[i, j].spines['left'].set_color(spines_color)\n        \n        # font dictionary\n        font3 = {'family': 'monospace', 'weight': 'bold', 'size': 14}\n        \n        # title for each plot\n        ax[i, j].set_title(team_ranks[ind], loc = 'left', x = 0.225, y = 1.08, fontproperties = ax_fps)\n        \n        # remove topmost and rightmost gridlines:\n        # retrieve all x and y gridlines\n        y_gridlines = ax[i, j].get_ygridlines()\n        x_gridlines = ax[i, j].get_xgridlines()\n        # select topmost and rightmost and remove them\n        y_last = y_gridlines[-1]\n        y_last.set_visible(False)\n        x_last = x_gridlines[-1]\n        x_last.set_visible(False)\n        \n        # club logo settings:\n        club_logo = image.imread(\"images/club_logos/\" + files[ind])\n        # add into image box\n        club_logo = OffsetImage(club_logo, zoom = 0.04)\n        # assign axis to image box\n        club_logo.image.axes = ax[i, j]\n        # set coordinates\n        ab = AnnotationBbox(club_logo, xy = (0.065, 1.16), xycoords = 'axes fraction', frameon = False)\n        # add to axis\n        ax[i, j].add_artist(ab)\n        \n        # update index for a list of teams\n        ind = ind + 1\n        \n\n# league logo settings:\nleague_img = image.imread(\"images/other_logos/allsvenskan_logo.png\")\nleague_logo = fig.add_axes([0.88, 0.88, 0.1, 0.1])\nleague_logo.set_axis_off()\nleague_logo.imshow(league_img, aspect = \"equal\")        \n\n# figure title and labels\nfig.supxlabel('xG Against', fontproperties = label_fps, y = 0.04)\nfig.supylabel('xG For', fontproperties = label_fps, x = 0.1)\nfig.suptitle('ALLSVENSKAN | 2021 SEASON', x = 0.485, y = 0.94, fontproperties = fig_fps)\n\n# annotations and logo for data source\nfig.text(0.01, 0.015, r\"data source:\", fontproperties = ds_fps)\nds_img = image.imread(\"images/other_logos/plm.png\")\nds_logo = fig.add_axes([0.08, 0.001, 0.05, 0.05])\nds_logo.set_axis_off()\nds_logo.imshow(ds_img, aspect = \"equal\") \n\n# author annotations:\nfig.text(0.85, 0.015, r\"author: Farid Musayev\", fontproperties = ds_fps)\n\n# create a space for a title and left/right axis\nfig.subplots_adjust(bottom = 0.085, top = 0.83)\n\nplt.show()\n\n# save figure\nfig.savefig('xg_subplots.png', dpi = 350, transparent = False)\n\n\n\n\nTo view this plot in a high resolution, please follow this link."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Projects",
    "section": "",
    "text": "Expected Goals Model | Scientific Visualization | Soccer Analytics"
  },
  {
    "objectID": "p2.html",
    "href": "p2.html",
    "title": "Soccer Analytics",
    "section": "",
    "text": "In this visualization, I make a gridplot of xG values conceded and scored by each team against all other teams in Allsvenskan (Swedish Top Football League) during season 2021. Since this is a gridplot, one can obtain only a general performance overview for each team. This gridplot was designed using object-oriented plotting in matplotlib.\nCode is available here.\n\nTo view this plot in a high resolution, please follow this link."
  },
  {
    "objectID": "p2.html#expected-threat-model",
    "href": "p2.html#expected-threat-model",
    "title": "Soccer Analytics",
    "section": "Expected Threat model",
    "text": "Expected Threat model\nIn this article, I step by step demonstrate how to build a simple Expected Threat (xT) model."
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Farid Musayev",
    "section": "",
    "text": "matplotlib\n\n\nsklearn\n\n\n\n\nhow to understand this life ?\n\n\n\n\n\n\nAug 14, 2022\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\npython\n\n\npandas\n\n\n\n\nhow to understand this life ?\n\n\n\n\n\n\nAug 14, 2022\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "report.html",
    "href": "report.html",
    "title": "Expected Threat Model",
    "section": "",
    "text": "The aim of this report is to build an Expected Threat (xT) Model and illustrate how it can be applied to evaluate performance of players that play from the deeper zones, mainly participate in the game build-up and can be overlooked by the traditional statistics like goals or assists or more advanced ones like Expected Goals (xG) or Expected Assists (xA)."
  },
  {
    "objectID": "report.html#introduction",
    "href": "report.html#introduction",
    "title": "Expected Threat Model",
    "section": "Introduction",
    "text": "Introduction\nGoals and assists are traditional statistics in soccer which focus on player’s shooting and creative capabilities. They concentrate on the assessment of only goal-oriented skills of the player. However, there can be play sequences in soccer that do not end with shots and sometimes lack a final accurate pass or touch that could have put another player into a shooting position. In such circumstances, the evaluation of the game build-up is still important. The actions of players who generate these kind of situations on field should be quantifiable to understand the threatening degree of those situations, and see if a player could have made a better decision. Quantification of these actions can also help to assess impact of players who participate in the game build-up and do not often find themselves close to the opponent’s goal.\nThere are advanced metrics for the evaluation of players that participate in the game build-up such as xGChain and xGBuildup. However, the problem with these metrics is that the xG value of a resulting shot is divided equally among all participants involved in a play sequence (in case of xGBuildup, all players, except assisting and sh0oting ones, are included). These metrics also fail to capture non-shot ending game scenarios.\nIt is worth mentioning that there are also other well known models (Posession Value Framework, VAEP etc.) which can be used as alternatives to xT model and are widely implemented in soccer analytics today.\nThis report illustrates a simple implementation of xT model that accounts only for passes that increase team’s probability of scoring. Considering that each pass has an impact on team’s probability of scoring, we are able to evaluate how threatining is the pass and assign it a certain value.\nThis model was originally introduced by Karun Singh in his blog post from 2019. Despite being written as a blog post, it gained a strong recognition from the soccer analytics community and was cited in different research papers. A grop of researchers from DTAI Sports Analytics Lab at KU Leuven University published a paper where they were comparing xT Model to VAEP framework."
  },
  {
    "objectID": "report.html#algorithm",
    "href": "report.html#algorithm",
    "title": "Expected Threat Model",
    "section": "Algorithm",
    "text": "Algorithm\nxT model represents a soccer pitch as a 12 x 16 grid where each section of a grid has an assigned xT value. This value is defined as a probability of a team scoring within n next actions. When a player passes from \\((x_{start}, y_{start})\\) to \\((x_{end}, y_{end})\\) coordinate, a completed pass generates so called xT difference that allows to quantify its impact and understand how a team’s probability of scoring changes.\nBelow you can see xT grid that was calculated in the course of this report. Here, each zone of the grid contains a value that implies a team’s probability of scoring in 5 next actions. One may consider higher/lower number of actions but the important point is to observe convergence of xT values in the attacking area, and increasing probability the defending area. More actions would mean that a team can spend more time preparing an attack and gradually progressing further which results into a greater probability of scoring when starting from its own half.\n\n\nCode\nplot_xT()\n\n\n\n\n\nTo calculate xT value for each coordinate (x, y) on the pitch, the following equation is used:\n\\[\\begin{equation}\nxT_{x,y} = s_{x,y}\\cdot xG_{x,y} + m_{x, y} \\cdot T_{x,y} \\cdot xT\n\\end{equation}\\]\nwhere\n\\(xT_{x,y}\\) - xT value for (x, y) coordinate\n\\(s_{x,y}\\) - probability of shooting from (x, y) coordinate\n\\(xG_{x,y}\\) - probability of scoring from (x, y) coordinate (expected goals value)\n\\(m_{x, y}\\) - probability of passing from (x, y) coordinate\n\\(T_{x, y}\\) - probability of passing from (x, y) coordinate to all other locations (transition matrix)\n\\(xT\\) - matrix of xT values for all (x, y) coordinates\nThe intuition is that for a player located at (x, y) coordinate, there are two choices: shooting or passing. These are mutually exclusive events that have corresponding probabilities of occurrence. Given that a player shoots with \\(s_{x, y}\\), probability of scoring for that shot will be \\(xG_{x, y}\\). Given that player passes with \\(m_{x, y}\\), expected payoff from that pass will be \\(T_{x, y} \\cdot xT\\). From (x, y) coordinate, a player has many options for passes, thus, different probabilities of passing to other areas (which are represented in the form of transition matrix \\(T_{x,y}\\)). In addition, each of those passing choices would have their own reward in the form of \\(xT\\) value. Thus, to calculate expected payoff of passing from (x, y), transition matrix from a given (x,y) is multiplied by a matrix of xT values of the whole pitch.\n\nMarkov Chains Perspective\nWe can view the above formula from the Markov Chains Perspective in the following way. Let us leave aside the left side of the formula and focus on the right side \\(T_{x,y} \\cdot xT\\). Here, we observe transition matrix that stores transition probabilities for a player deciding to pass from (x, y) to all other locations on the grid. To evaluate the expected payoff of a completed pass from each (x,y), we also start with initial matrix of xT values.\nAs we know from the behavior of irreducible and aperiodic Markov Chains, as transition matrix is multiplied by itself infinite amount of times and some initial starting state, one can observe convergence to the stationary distribution. This actually illustrates that it does not matter what is that initial starting state. In the above formula, we view our matrix of xT values as an initial starting state of all 0 values and iteratively multiply it by transition matrix.\nIn our specific case, as the number of iterations increase, one can observe convergence of xT values in more threating zones and increasing probability mass in less threatening zones. A number of iterations equals a number of subsequent actions after which a team scores a goal. This explains why a probability mass increases in less threatening zones (in the own half of the team in possesion) since more actions mean more time for abuild-up and preparation of an attack from the own half of a team in possession."
  },
  {
    "objectID": "report.html#data",
    "href": "report.html#data",
    "title": "Expected Threat Model",
    "section": "Data",
    "text": "Data\nWyscout Soccer Match Event dataset from 2017/2018 English Premier League (EPL) is used to build xT model.\n\n\nCode\nwyscout_data.competitions()\n\n\n\n\n\n\n  \n    \n      \n      competition_id\n      season_id\n      country_name\n      competition_name\n      competition_gender\n      season_name\n    \n  \n  \n    \n      0\n      524\n      181248\n      Italy\n      Italian first division\n      male\n      2017/2018\n    \n    \n      1\n      364\n      181150\n      England\n      English first division\n      male\n      2017/2018\n    \n    \n      2\n      795\n      181144\n      Spain\n      Spanish first division\n      male\n      2017/2018\n    \n    \n      3\n      412\n      181189\n      France\n      French first division\n      male\n      2017/2018\n    \n    \n      4\n      426\n      181137\n      Germany\n      German first division\n      male\n      2017/2018\n    \n    \n      5\n      102\n      9291\n      International\n      European Championship\n      male\n      2016\n    \n    \n      6\n      28\n      10078\n      International\n      World Cup\n      male\n      2018\n    \n  \n\n\n\n\nSpecifically, match event dataset is used to evaluate \\(xG_{x, y}\\), \\(s_{x, y}\\), \\(m_{x, y}\\) and \\(T_{x, y}\\) (see next sections).\nSee Appendix section A2. Event Data Preprocessing for full code on data preparation."
  },
  {
    "objectID": "report.html#xg-model",
    "href": "report.html#xg-model",
    "title": "Expected Threat Model",
    "section": "xG Model",
    "text": "xG Model\nThis section illustrates a methodology for implementing xG model that is used to evaluate \\(xG_{x, y}\\) for a given (x, y) coordinate on the pitch.\n\nShots Data\nAfter data preprocessing steps, we filter out all 7134 shots for EPL 2017/2018 season (see A3.1 Filter Shots).\n\n\nCode\nshots.head()\n\n\n\n\n\n\n  \n    \n      \n      player_id\n      type_id\n      type_name\n      subtype_id\n      subtype_name\n      tag_id\n      tag_name\n      x_start\n      y_start\n      x_end\n      y_end\n      outcome\n    \n  \n  \n    \n      0\n      25413\n      10\n      shot\n      100\n      shot\n      [101, 402, 201, 1205, 1801]\n      ['goal', 'right foot', 'opportunity', 'positio...\n      88\n      41\n      0.0\n      0.0\n      1\n    \n    \n      1\n      26150\n      10\n      shot\n      100\n      shot\n      [401, 201, 1211, 1802]\n      ['left foot', 'opportunity', 'position: out ce...\n      85\n      52\n      100.0\n      100.0\n      0\n    \n    \n      2\n      7868\n      10\n      shot\n      100\n      shot\n      [401, 201, 1215, 1802]\n      ['left foot', 'opportunity', 'position: out hi...\n      81\n      33\n      0.0\n      0.0\n      0\n    \n    \n      3\n      7868\n      10\n      shot\n      100\n      shot\n      [402, 201, 1205, 1801]\n      ['right foot', 'opportunity', 'position: goal ...\n      75\n      30\n      0.0\n      0.0\n      0\n    \n    \n      4\n      7945\n      10\n      shot\n      100\n      shot\n      [401, 2101, 1802]\n      ['left foot', 'blocked', 'not accurate']\n      90\n      39\n      0.0\n      0.0\n      0\n    \n  \n\n\n\n\n\n\nCode\n# (number of shots, number of features)\nshots.shape\n\n\n(7134, 12)\n\n\n\n\nFeature Generation\nTo calculate xG model, we have to create two features distance to goal and angle of shot (see also A3.2 Feature Generating Function).\n\n\nCode\n# Distance Feature calculation\n\n# define goal center for 'wyscout' data\ngoal_center = np.array([100, 50])\n\n# calculate distance between shot and goal center\nshots['distance'] = np.sqrt((shots['x_start'] - goal_center[0])**2 + (shots['y_start'] - goal_center[1])**2)\nshots['distance'] = shots['distance'].round(decimals = 2)\n\n\n\n\nCode\n# Angle Feature calculation\n\n# transform x, y coordinates from percentiles to field length coordinates (105 meters x 68 meters)\nx = shots['x_start'] * 105/100\ny = shots['y_start'] * 68/100 \n\n# Use trigonometric formula to find angle between two sides (a,b ) of triangle where third side (c) \n# is a goal line of length 7.32 m\na = np.sqrt((x - 105)**2 + (y - 30.34)**2) # length between right post and (x,y) shot coordinate\nb = np.sqrt((x - 105)**2 + (y - 37.66)**2) # length between left post and (x,y) shot coordinate\nc = 7.32 # goal line length\ncos_alpha = (a**2 + b**2 - c**2)/(2*a*b)\ncos_alpha = np.round(cos_alpha, decimals = 4)\n\n# remember to leave angle in radians (if you want to transfer to degree multiply cos_alpha by 180/pi)\nshots['angle'] = np.arccos(cos_alpha)\n\n\n\n\nModel Training with Logistic Regression\nThen, we use Logistic Regression to fit our data and create xG model.\n\n\nCode\n# Prepare features and labels from available data\nfeatures = shots[['distance', 'angle']]\nlabels = shots['outcome']\n\n# Fit Logistic Regression Model\nfrom sklearn.linear_model import LogisticRegression\nxG_model = LogisticRegression()\nxG_model.fit(features, labels)\n\n# save predictions\npredictions = xG_model.predict_proba(features)[:, 1]\n\n\nBelow is a plot of a number of shots versus predictions. This allows to see that only a small fraction of shots has a high probability of scoring which makes sense.\n\n\nCode\nplot_predictions()\n\n\n\n\n\n\n\nModel Performance Evaluation\nModel performance evaluation is implemented using ROC curve (for details see A3.3 xG Model Evaluation with ROC).\n\n\nCode\nplot_roc()\n\n\n\n\n\n\n\nCode\n# evaluate area under ROC curve using Python function roc_auc_score()\nroc_auc_score(ndf['outcome'], ndf['xG'])\n\n\n0.7843416803145005\n\n\nWe see that ROC value 0.784 is well above random guess (>> 0.5) which is an indicator of a satisfactory model performance."
  },
  {
    "objectID": "report.html#xt-equation-variables",
    "href": "report.html#xt-equation-variables",
    "title": "Expected Threat Model",
    "section": "xT Equation Variables",
    "text": "xT Equation Variables\nIn section 3, xT equation variables \\(s_{x, y}\\), \\(m_{x, y}\\), \\(xG_{x, y}\\) were defined. Below you can see obtained results for each of these variables (see A4. xT Equation Variables Derivation).\nAll of the results were obtained in the form of 12x16 matrix which was illustrated as a pitch heatmap.\n\nProbability Shooting \\(s_{x, y}\\)\nThis heatmap illustrates probability of shooting \\(s_{x, y}\\) from a given (x, y). Naturally, as a player approaches an opponent’s goal, \\(s_{x, y}\\) increases.\n\n\nCode\nplot_shot_probs()\n\n\n\n\n\n\n\nProbability of Passing \\(m_{x, y}\\)\nThis heatmap illustrates probability of passing \\(m_{x, y}\\) from a given (x, y). Naturally, as a player approaches an opponent’s goal, \\(m_{x, y}\\) decreases, since a player becomes more inclined to shooting.\n\n\nCode\nplot_pass_probs()\n\n\n\n\n\n\n\nProbability of Scoring \\(xG_{x, y}\\)\nThis heatmap illustrates probability of scoring \\(xG_{x, y}\\) from a given (x, y). Naturally, as a player approaches an opponent’s goal, the distance to a goal decreases and the angle of a shot increases, thus, \\(xG_{x, y}\\) increases.\n\n\nCode\nplot_score_probs()\n\n\n\n\n\n\n\nTransition Matrix \\(T_{x, y}\\)\nBelow you can see a function transition_matrix()that for a given (x, y) coordinate calculates a probability of passing to all other (x, y) coordinates (transition probabilities) and stores them inside a matrix.\n\n\nCode\ndef transition_matrix(x, y):\n    # empty matrix for storing transition probabilities\n    transition_matrix = np.zeros(shape = (12, 16))\n    \n    # from passes data frame filter out only passes with initial (x, y) equal to a given (x, y)\n    transition_passes = passes[(passes[\"x_start_bin\"] == x) & (passes[\"y_start_bin\"] == y)]\n    \n    # iterate over all filtered passes and count passes with equal (x, y)\n    for i in range(transition_passes.shape[0]):\n        row_ind = transition_passes[\"y_end_bin\"].iloc[i]\n        col_ind = transition_passes[\"x_end_bin\"].iloc[i]\n        transition_matrix[row_ind, col_ind] = transition_matrix[row_ind, col_ind] + 1\n    \n    # divide counts for each (x, y) by the total number of passes to calculate probabilities\n    transition_matrix = transition_matrix/transition_passes.shape[0]\n    return transition_matrix"
  },
  {
    "objectID": "report.html#xt-algorithm-implementation",
    "href": "report.html#xt-algorithm-implementation",
    "title": "Expected Threat Model",
    "section": "xT Algorithm Implementation",
    "text": "xT Algorithm Implementation\nFinally, using all the above estimated probabilities we can evaluate our xT values for all (x, y) coordinates of the pitch.\n\n\nCode\n# xT algorithm\nxT = np.zeros(shape = (12, 16))\n\n# 5 iterations\nfor i in range(5):\n    for x in range(16):\n        for y in range(12):\n            # evaluate transition matrix for a given (x, y)\n            T_matrix = transition_matrix(x, y)\n            \n            # evaluate xT value for a given (x, y) using equation from section 3\n            xT[y, x] = shot_probs[y, x] * score_probs[y, x] + pass_probs[y, x] * np.sum(T_matrix * xT)\n\n# round and save results\nit5 = pd.DataFrame(xT).round(decimals = 3)\n#it5.to_csv('xT_grid.csv', index = False)    \n\n\n\n\nCode\nplot_xT()"
  },
  {
    "objectID": "report.html#results-and-discussion",
    "href": "report.html#results-and-discussion",
    "title": "Expected Threat Model",
    "section": "Results and Discussion",
    "text": "Results and Discussion\nWe make a sanity check of our model by comparing and plotting xT values of the players across Bundesliga, EPL, LaLiga and Ligue 1 from 2017/2018 season using Wyscout Soccer Match Event Dataset.\nBarplots on the left illustrate xT values of top 10 players in the league. Barplots on the right illustrate xT values of top 10 young players among all league players aged under 21. Since the data is from 2017/2018 season, this allows us to track how the careers of young players actually developed given a single successful (according to xT) season.\nSee A5. Plot Functions for the code for all plots in the following sections.\n\nBundesliga\nFor Bundesliga, top 10 performers are mainly midfielders and defenders. Thiago Alcantara is well known as one of the most technically gifted players in the european football. He plays as the central midfielder, and, naturally, does not register a high number of goals and assists (2 league goals and 2 assists in 2017/2018) in his statistics. Nevertheless, he is the top performer in terms of xT per 90 equal to 0.56 according to our model (which means that, on average, his passes increase his team’s probability of scoring by 0.56 per game). It makes sense to see Alcantara in the top 10 of our bar graph, since he is well known for a high ability to control the game in the central area and initiate attacks with line-breaking passes (the ones that may cut through and leave behind several players of opponent’s team). There are also players similar to Alcantara’s profile such as Nuri Sahin (2 goals, 2 assists), Charles Aranguiz (1 goal, 3 assists) who also found their place in our top 10.\nCentral defenders also have a dominant presence in our xT bar graph. Given that they spend a large amount of time on field, in some scenarios, this can lead to a high number of aggregated small xT values. Thus, it is always important to normalize values per a single game ( per 90 minutes). Apart from that, modern central defenders should be capable of initiating their team’s attacks with a great first pass (line-breaking pass, switch etc.). Players like Jerome Boateng and Mats Hummels are, in particular, appreciated for this kind of passes.\nAs stated previously, we can assess xT performance of young players and basing on a sinlge season success track their further career development. For example, Dayot Upamecano had a first breakthrough season in RB Leipzig (top of our xT bar graph) and after three more years of a consistent performance moved to Bayern Munich. During 2017/2018, Kai Havertz was already having his second full season in a senior football being 19 years old. He had two more successful seasons (29 goals, 9 assists) in Bayern Leverkusen and, then, moved to Chelsea. Panagiotis Retsos had a breakthrough season at Bayern Leverkusen as a right full back but suffered three serious injuries which kept him out of the game for the majority of the next season. This obivously had a serious impact on his career, and, so far, he struggled to regain his form during loan spells in England, France and Italy.\n\n\nCode\nplot_bundesliga()\n\n\n\n\n\n\n\nEPL\nIn contrast with Bundesliga, top 10 EPL performers are mainly central and attacking midfielders and even a single wide playing forward. Starting from the latter, this is Alexis Sanchez, who made 74 shot creating passes in 2017/2018. In particular, he was also vital to his team for the ability to drop back into midfield and participate in the initiation of attacks.\nThe rest of top five (Cesc Fabregas, Kevin De Bruyne, Mesut Ozil, David Silva) are creative forces of their teams (0.70, 0.59, 0.57, 0.54 xT per 90). All four were generating the chances of at least a half goal per a game, and this does not even include the rest of their advaced statistics such as xG or xA. The bottom top five consists of more functional central midfielders (except attacking Phillipe Coutinho) whose xT values are close or slightly higher that 0.5. In other words, we observe that xT metric validates importance of these players for their teams.\nWhen having a look at the performance of young players, we can observe a rise of full backs such as Trent Alexander-Arnold, Ainsley Maitland-Niles, Timothy Fosu-Mensah and Ben Chilwell. Alexander-Arnold (0.32 xT per 90) is regarded one of the top performing full backs of the last three seasons (9 goals, 44 assists). He is known for his ability to initiate the attacks from the right half-space. As with senior players, we observe functional midfielders such as Wilfred Ndidi and Declan Rice in the bottom five of our bar graph. Being recognized for their defensive skills, these players are regular starters of their teams despite their young age.\n\n\nCode\nplot_epl()\n\n\n\n\n\n\n\nLaLiga\nSimilar to EPL, we mainly observe central and attacking midfielders among top 10 performers in LaLiga. However, one name stands out here, and that is Lionel Messi. Messi is known for his skills to drop deeper, participate in the game play in the central area and, then, run forward. This is one of the reasons why he managed to aggregate 0.59 xT per 90. Andres Iniesta and Ever Banega also have identical to Messi’s xT results and are an essential part of their teams during the possession. It is also interesting to see a left full back Marcelo with his 0.5 xT per 90. Though mainly playing from the left, he possess great passing skills which help to build and progress his team’s attacks.\nLaLiga’s top young players play in various positions from wingers and central midfielders to full backs and central defenders. Despite being largerly hit by injuries, Ousmane Dembele were able to demonstrate his potential with 0.28 xT per 90 in his first season for Barcelona. However, injuries still haunted him in the following seasons which, obviously, affected his career. Theo Hernandez impressed for Real Madrid as a left full back (0.22 xT per 90), despite a limited time, and, in the last three seasons, were a stable starting eleven player for Milan. Federico Valverde had a great season as a box-to-box midfielder (0.25 xT per 90) in his first season for Deportivo La Coruna, and, afterwards, earned his place in Real Madrid.\n\n\nCode\nplot_laliga()\n\n\n\n\n\n\n\nLigue 1\nWhen evaluating top 10 players from Ligue 1, we observe similar patterns as in LaLiga. The first place is reserved by Neymar with 0.62 xT per 90 who plays as a wide forward or attacking midfielder. There are also several deep-lying midfielders such as Marco Veratti, Yann M’vila, Thiago Motta and Jean Seri. Similar to Marcelo from LaLiga, Daniel Alves is the only full back in the list. Daniel Alves who operates from the right wing has always been a creative and technical player with great passing and ball progressing skills. In any of the teams in which he played, he has been instrumental to holding possession and movement of a ball to high threating areas.\nMaxime Lopez is the only player, out of four leagues that were reviewed, who earned his place in both senior and young players list with 0.51 xT per 90. Despite his young age of 19, 2017/2018 season was already his second season in senior football where he helped Marseille to achieve the fourth place in the league. He continued playing as a midfielder three more years for the french club but had a limited time in the last season. Thus, he was loaned to the italian team Sassuolo. Despite playing regularly there, he could not convince Marseille to bring him back and, eventually, stayed in Italy on the permanent basis.\n\n\nCode\nplot_ligue1()"
  },
  {
    "objectID": "report.html#conclusion",
    "href": "report.html#conclusion",
    "title": "Expected Threat Model",
    "section": "Conclusion",
    "text": "Conclusion\nAs it can be seen from the above results, xT Model demonstrates a good performance when trying to evaluate players who are overlooked by traditional or shot-oriented advanced statistics but are still important to their teams. These can be different types of players such as central defenders with a great first pass, deep-lying midfielders switching game with long ranging passes and creative full backs involved in possession. However, as it stands for all models, this model also has a room for improvement.\nBelow are suggestions for further studies of xT model: - add other action types such as carries and take-ons - account for actions with negative xT such as inaccurate passes or lost balls - use negative xT during player performance evaluation - normalize xT results per number of actions by a player"
  },
  {
    "objectID": "report.html#references",
    "href": "report.html#references",
    "title": "Expected Threat Model",
    "section": "References",
    "text": "References\n\nKarun Singh’s Expected Threat Model, 2019.\nRoy, Maaike Van, Pieter Robberechts, Tom Decroos and Jesse Davis. “Valuing On-the-Ball Actions in Soccer: A Critical Comparison of xT and VAEP.” (2020).\nJim Albert and Jingchen Hu, Probability and Bayesian Modelling, Ch. 9.2, Markov Chains, 2019.\nWyscout Soccer Match Event Dataset, 2019."
  },
  {
    "objectID": "report.html#appendix",
    "href": "report.html#appendix",
    "title": "Expected Threat Model",
    "section": "Appendix",
    "text": "Appendix\n\nA1. Libraries\n\n\nCode\n# import required libraries\nimport os\nimport ast\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom mplsoccer import Pitch, VerticalPitch\nimport matplotlib_inline\nfrom matplotlib import cm\n\n\n\n\nA2. Event Data Preprocessing\n\n\nCode\n# import public wyscout data loader from socceraction library\nfrom socceraction.data.wyscout import PublicWyscoutLoader \n\n# load public wyscout data\nwyscout_data = PublicWyscoutLoader()\n\n# import tags for uncode subevents in event data\ntags = pd.read_csv('wyscout_tags.csv', sep = ';')\n\n# make all descriptions lowercase\ntags['Description'] = tags['Description'].str.lower()\n\n# transform tags data frame into dictionary\ntags = dict(zip(tags['Tag'], tags['Description']))\n\n\n\n\nCode\n# England 17/18, competition_id = 364, season_id = 181150\nepl_games = wyscout_data.games(competition_id = 364, season_id = 181150)[\"game_id\"]\n\n\n##################################################################################################\n# Below sections were executed a single time and saved as .csv files (only comment out if needed)#\n##################################################################################################\n# Section 1.\n# convert all premier league matches to SPADL format and save as .csv files\n#for i in epl_games:\n#    df = wyscout_data.events(i)\n#    df.to_csv(f'epl_games/{i}.csv')\n\n###################################################################################################\n# Section 2.\n# concate all .csv files aka 'game ids' into a single data frame and save events.csv\n\n# list of all game ids\n#files = os.listdir('epl_games/.')\n\n#events = pd.DataFrame()\n#for i in files:\n#    df = pd.read_csv(f'epl_games/{i}')\n#    events = pd.concat([events, df])\n#events.to_csv(f'events.csv', index = False)    \n\n## This code refines all events for the specific task\n\n# upload 'events' data frame that includes events of all 380 EPL games\ndf = pd.read_csv('events.csv')\n\n# create column indices to be removed\nrm_col_ind = np.r_[0:6]\ndf = df.drop(columns = df.columns[rm_col_ind])\n\n# convert strings into python lists\ndf['tags'] = df['tags'].apply(ast.literal_eval)\ndf['positions'] = df['positions'].apply(ast.literal_eval)\n\n# make 'type_name' and 'subtype_name' columns lowercase \ndf['type_name'] = df['type_name'].str.lower()\ndf['subtype_name'] = df['subtype_name'].str.lower()\n\n# create separate initial(start) and final(end) coordinates from 'positions' column\n# if action has only 'start' coordinates set 'end' coordinates to 'nan'\ndf['x_start'] = df['positions'].apply(lambda x: x[0]['x'])\ndf['y_start'] = df['positions'].apply(lambda x: x[0]['y'])\ndf['x_end'] = df['positions'].apply(lambda x: x[1]['x'] if len(x) == 2 else np.nan)\ndf['y_end'] = df['positions'].apply(lambda x: x[1]['y'] if len(x) == 2  else np.nan)\n\n# use dictionaries and list comprehensions to convert tags into tag ids and their descriptions \ndf['tag_id'] = df['tags'].apply(lambda x: [value for d in x for value in d.values()])\ndf['tag_name'] = df['tag_id'].apply(lambda x: [tags[i] for i in x])\n\n\n# drop redundant column 'positions'\ndf.drop(columns = ['positions', 'tags'], inplace=True)\n\n# rearrange columns\nrearr_cols = np.r_[0:5, 9, 10, 5:9]\ndf = df.iloc[:, rearr_cols]\n\n# save 'df' as 'refined_events.csv' data frame\ndf.to_csv('refined_events.csv', index = False)    \n\n\n\n\nA3. xG Model\n\nA3.1 Filter Shots\n\n\nCode\ndf = pd.read_csv('epl/refined_events.csv')\ndf['tag_id'] = df['tag_id'].apply(ast.literal_eval)\ndf['tag_name'] = df['tag_name'].apply(ast.literal_eval)\n\n\n# free kicks are not included (penalties are also part of free kicks)\nshots = df[df['type_name'] == 'shot']\n\n# function for removing headers\ndef headers_out(x):\n    for i in x:\n        if i == 403:\n            return False\n            break\n    else:\n        return True\n\n# function for assigning shot outcomes as '1' or '0' (goal or no goal)\ndef goals(x):\n    for i in x:\n        if i == 101:\n            return 1\n            break\n    else:\n        return 0\n\n# remove headers from shots\nnon_headers = shots['tag_id'].apply(lambda x: headers_out(x))\nshots = shots[non_headers]\n# assign outcome to each shot\noutcome = shots['tag_id'].apply(lambda x: goals(x))\nshots['outcome'] = outcome\n\nshots.to_csv('epl/shots.csv', index = False)    \n\n\n\n\nCode\nshots = pd.read_csv('epl/shots.csv')\n\n\n\n\nA3.2 Feature Generating Function\n\n\nCode\n# Generate 'Angle' and 'Distance' features from x,y coordinates provided as a new input to our xG model\n\ndef generate_features(coords):\n    \n    # unpack tuple\n    x = coords[0]\n    y = coords[1]\n    \n    # Distance Feature calculation\n    # define goal center for 'wyscout' data\n    goal_center = np.array([100, 50])\n\n    # calculate distance between shot and goal center\n    distance = np.sqrt((x - goal_center[0])**2 + (y - goal_center[1])**2)\n    distance = distance.round(decimals = 2)\n\n\n    # Angle Feature calculation\n    # transform x, y coordinates from percentiles to field length coordinates (105 meters x 68 meters)\n    x = x * 105/100\n    y = y * 68/100 \n\n    # Use trigonometric formula to find angle between two sides (a,b ) of triangle where third side c is a goal line of length 7.32\n    a = np.sqrt((x - 105)**2 + (y - 30.34)**2) # length between right post and x,y shot coordinate\n    b = np.sqrt((x - 105)**2 + (y - 37.66)**2) # length between left post and x,y shot coordinate\n    c = 7.32 # goal line length\n    cos_alpha = (a**2 + b**2 - c**2)/(2*a*b)\n    cos_alpha = np.round(cos_alpha, decimals = 4)\n\n    # remember to leave angle in radians (if you want to transfer to degree multiply cos_alpha by 180/pi)\n    angle = np.arccos(cos_alpha).round(decimals = 2)\n    # return 'distance' and 'angle' features as numpy array\n    return np.array([distance, angle])\n\n\n\n\nA3.3 xG Model Evaluation with ROC\n\n\nCode\ndef plot_predictions():\n    plt.figure(figsize = (5, 3))\n    plt.plot(sorted(predictions))\n    plt.xlabel('number of shots')\n    plt.ylabel('probabiliy of scoring')\n    plt.show()\n\n\n\n\nCode\nndf = pd.concat([features, labels], axis = 1)\nndf = ndf.reset_index()\nndf.drop(\"index\", axis = 1, inplace=True)\nndf[\"xG\"] = xG_model.predict_proba(features)[:, 1]\n\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import roc_auc_score\n\n# define range for threshold value\nn = 100\n  \n# create row for checking each value with 'r' threshold values\nndf['sim_outcome'] = np.zeros(shape = (ndf.shape[0], 1))\n# create container matrix for FPR and TPR\nroc_matrix = np.zeros(shape = (100, 3))\n# 'r' threshold values for probability \nthresholds = np.arange(0, 1, 1/n)\n# save threshold values as the first row\nroc_matrix[:, 0] = thresholds\n\nfor i, m in enumerate(thresholds):\n    ndf['sim_outcome'] = ndf['xG'].apply(lambda x: 1 if x > m else 0)\n    TN, FP, FN, TP = confusion_matrix(ndf['outcome'], ndf['sim_outcome']).ravel()\n    roc_matrix[i, 1] = FP/(TN + FP) # false positive rate\n    roc_matrix[i, 2] = TP/(TP + FN) # true positive rate\n\n# plot ROC curve\ndef plot_roc():\n    fig, ax = plt.subplots(figsize = (4, 4))\n    ax.grid(color='black', ls = '-.', lw = 0.4, which = 'major')\n    ax.plot(roc_matrix[:, 1], roc_matrix[:, 2], zorder = 2)\n    ax.plot([0, 1], [0, 1], ls = '--')\n    ax.set_xlabel(\"false positive rate\")\n    ax.set_ylabel(\"true positive rate\")\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    ax.spines[['top', 'right']].set_visible(False)\n    ax.legend(labels = ['xG Model', 'Random Guess'], loc = 4,\n              #bbox_to_anchor=(1.0, 0.1, 0.5, 0.5),\n             frameon = True)\n    plt.show()\n\n\n\n\n\nA4. xT Equation Variables Derivation\n\nA4.1 Shooting Probability\n\n\nCode\nx_intervals = np.linspace(0, 100, 17)\ny_intervals = np.linspace(0, 100, 13)\n\nshots[\"x_start_bin\"] = pd.cut(shots[\"x_start\"], bins = x_intervals, include_lowest=True, labels = False)\nshots[\"y_start_bin\"] = pd.cut(shots[\"y_start\"], bins = y_intervals, include_lowest=True, labels = False)\n\nshots[\"x_end_bin\"] = pd.cut(shots[\"x_end\"], bins = x_intervals, include_lowest=True, labels = False)\nshots[\"y_end_bin\"] = pd.cut(shots[\"y_end\"], bins = y_intervals, include_lowest=True, labels = False)\n\nshot_counts = np.zeros(shape = (12, 16))\nfor i in range(shots.shape[0]):\n    row_ind = shots[\"y_start_bin\"].iloc[i]\n    col_ind = shots[\"x_start_bin\"].iloc[i]\n    shot_counts[row_ind, col_ind] = shot_counts[row_ind, col_ind] + 1\n\n\n\n\nA4.2 Passing Probability\n\n\nCode\ndf = pd.read_csv('epl/refined_events.csv')\ndf['tag_id'] = df['tag_id'].apply(ast.literal_eval)\ndf['tag_name'] = df['tag_name'].apply(ast.literal_eval)\n\n\n\n\nCode\n# free kicks are not included (penalties are also part of free kicks)\npasses = df[df['type_name'] == 'pass']\n\npasses[\"x_start_bin\"] = pd.cut(passes[\"x_start\"], bins = x_intervals, include_lowest=True, labels = False)\npasses[\"y_start_bin\"] = pd.cut(passes[\"y_start\"], bins = y_intervals, include_lowest=True, labels = False)\n\npasses[\"x_end_bin\"] = pd.cut(passes[\"x_end\"], bins = x_intervals, include_lowest=True, labels = False)\npasses[\"y_end_bin\"] = pd.cut(passes[\"y_end\"], bins = y_intervals, include_lowest=True, labels = False)\n\n# save accurate passes as .csv file\npasses.to_csv('epl_passes.csv', index = False)      \n\n\n\n\nCode\npasses = pd.read_csv('epl/epl_passes.csv')\n\npass_counts = np.zeros(shape = (12, 16))\nfor i in range(passes.shape[0]):\n    row_ind = passes[\"y_start_bin\"].iloc[i]\n    col_ind = passes[\"x_start_bin\"].iloc[i]\n    pass_counts[row_ind, col_ind] = pass_counts[row_ind, col_ind] + 1\n\n\n\n\nCode\n# pass probabilities\npass_probs = pass_counts/(pass_counts + shot_counts)\n# shot probabilities\nshot_probs = shot_counts/(pass_counts + shot_counts)\n\n\n\n\nA4.3 Scoring Probability\n\n\nCode\nx_grid = np.linspace(0, 100, 160)\ny_grid = np.linspace(0, 100, 120)\n\n# scoring probability for \nxG_values = np.zeros(shape = (120, 160))\nfor i in range(len(x_grid)):\n    for j in range(len(y_grid)):\n        #print(i, j)\n        k = x_grid[i], y_grid[j]\n        f1 = generate_features(k)\n        xG_values[j, i] = xG_model.predict_proba(f1.reshape(1, -1))[:, 1]\n        \n# 12 x 16 grid without averaging\nunrefined_xg = pd.DataFrame(xG_values)\n\nrefined_xg = np.zeros(shape = (12, 16))\nx_len = xG_values.shape[1] + 1\ny_len = xG_values.shape[0] + 1\n\nrow_ind = 0\nfor j in range(10, y_len, 10):\n    col_ind = 0\n    for i in range(10, x_len, 10):\n        avg_result = unrefined_xg.iloc[(j - 10):j, (i - 10):i].values.mean()\n        refined_xg[row_ind, col_ind] = avg_result\n        col_ind = col_ind + 1\n    row_ind = row_ind + 1\n\n# scoring probabilities derived from xG model\nscore_probs = refined_xg.round(decimals = 2)\n\n\n\n\n\nA5. Plot Functions\n\nA5.1 xT values Grid\n\n\nCode\nmatplotlib_inline.backend_inline.set_matplotlib_formats('svg')\n\ndef plot_xT():\n\n    # import xT values as .csv file\n    xT_grid = pd.read_csv('xT_grid.csv')\n\n    # transform xT grid into a shap\n    xT_transform = np.zeros(shape = (192, 3))\n    count = 0\n    for i, y in xT_grid.iterrows():\n        for j, x in xT_grid.iteritems():\n            xT_transform[count, :] = np.array([i, j, xT_grid.iloc[int(i), int(j)]])\n            count = count + 1\n    xT_transform = pd.DataFrame(xT_transform)\n    xT_transform.reset_index(drop = True, inplace = True)\n    xT_transform.columns = ['x', 'y', 'value']\n\n\n    # Canvas\n    fig, ax = plt.subplots(figsize = (8, 8))\n\n    # Heatmap\n    pitch = Pitch(pitch_type='wyscout', line_zorder=1,\n                  pitch_color='white', line_color='black', linewidth = 0.5)\n\n    pitch.draw(ax = ax)\n    bin_statistic = pitch.bin_statistic(xT_transform.x, xT_transform.y, statistic='count', bins=(16, 12))\n    bin_statistic['statistic'] = xT_grid.to_numpy()\n    pt = pitch.heatmap(bin_statistic, ax = ax, cmap='Reds', edgecolor = '#EBDECE')\n    pitch.label_heatmap(bin_statistic, color='#736B65', fontsize=7, ax = ax, ha='center', va='center', zorder = 2)\n\n\n    # Arrow \n    arrow_ax = fig.add_axes([0.30, 0.20, 0.35, 0.3]) # X, Y, width, height\n\n    arrow_ax.arrow(0.45, 0.1, 0.30, 0, head_width=0.03, head_length=0.03, linewidth=4, \n               color='darkgrey', length_includes_head=True)\n    arrow_ax.set_ylim(0, 1)\n    arrow_ax.set_xlim(0, 1)\n    arrow_ax.set_axis_off()\n    arrow_ax.annotate('Direction of Play', xy = (0.42, 0.02), fontsize = 10)\n\n\n    # Colorbar\n    ax_cbar = fig.add_axes((0.95, 0.3, 0.03, 0.4))\n    fig.colorbar(pt, cax = ax_cbar).set_label(label = 'xT values', size=10)\n\n    #\n    plt.show()\n\n\n\n\nA5.2 Passing Probability\n\n\nCode\ndef plot_pass_probs():\n\n    # import probability of passing as .csv file\n    xT_grid = pd.DataFrame(pass_probs.round(decimals = 2))\n\n    # transform xT grid into a shap\n    xT_transform = np.zeros(shape = (192, 3))\n    count = 0\n    for i, y in xT_grid.iterrows():\n        for j, x in xT_grid.iteritems():\n            xT_transform[count, :] = np.array([i, j, xT_grid.iloc[int(i), int(j)]])\n            count = count + 1\n    xT_transform = pd.DataFrame(xT_transform)\n    xT_transform.reset_index(drop = True, inplace = True)\n    xT_transform.columns = ['x', 'y', 'value']\n\n\n    # Canvas\n    fig, ax = plt.subplots(figsize = (8, 8))\n\n    # Heatmap\n    pitch = Pitch(pitch_type='wyscout', line_zorder=1,\n                  pitch_color='white', line_color='black', linewidth = 0.5)\n    \n    # getting the original colormap using cm.get_cmap() function\n    orig_map=plt.cm.get_cmap('YlOrRd')\n  \n    # reversing the original colormap using reversed() function\n    reversed_map = orig_map.reversed()\n\n    pitch.draw(ax = ax)\n    bin_statistic = pitch.bin_statistic(xT_transform.x, xT_transform.y, statistic='count', bins=(16, 12))\n    bin_statistic['statistic'] = xT_grid.to_numpy()\n    pt = pitch.heatmap(bin_statistic, ax = ax, cmap = reversed_map, edgecolor = '#EBDECE')\n    pitch.label_heatmap(bin_statistic, color='black', fontsize=7, ax = ax, ha='center', va='center', zorder = 2)\n\n\n    # Arrow \n    arrow_ax = fig.add_axes([0.30, 0.20, 0.35, 0.3]) # X, Y, width, height\n\n    arrow_ax.arrow(0.45, 0.1, 0.30, 0, head_width=0.03, head_length=0.03, linewidth=4, \n               color='darkgrey', length_includes_head=True)\n    arrow_ax.set_ylim(0, 1)\n    arrow_ax.set_xlim(0, 1)\n    arrow_ax.set_axis_off()\n    arrow_ax.annotate('Direction of Play', xy = (0.42, 0.02), fontsize = 10)\n\n\n    # Colorbar\n    ax_cbar = fig.add_axes((0.95, 0.3, 0.03, 0.4))\n    fig.colorbar(pt, cax = ax_cbar).set_label(label = '$m_{x, y}$, probability of passing', size=10)\n\n    #\n    plt.show()\n\n\n\n\nA5.3 Shooting Probability\n\n\nCode\ndef plot_shot_probs():\n\n    # import probability of shooting as .csv file\n    xT_grid = pd.DataFrame(shot_probs.round(decimals = 2))\n\n    # transform xT grid into a shap\n    xT_transform = np.zeros(shape = (192, 3))\n    count = 0\n    for i, y in xT_grid.iterrows():\n        for j, x in xT_grid.iteritems():\n            xT_transform[count, :] = np.array([i, j, xT_grid.iloc[int(i), int(j)]])\n            count = count + 1\n    xT_transform = pd.DataFrame(xT_transform)\n    xT_transform.reset_index(drop = True, inplace = True)\n    xT_transform.columns = ['x', 'y', 'value']\n\n\n    # Canvas\n    fig, ax = plt.subplots(figsize = (8, 8))\n\n    # Heatmap\n    pitch = Pitch(pitch_type='wyscout', line_zorder=1,\n                  pitch_color='white', line_color='black', linewidth = 0.5)\n    \n    # getting the original colormap using cm.get_cmap() function\n    orig_map=plt.cm.get_cmap('YlOrRd')\n  \n    # reversing the original colormap using reversed() function\n    reversed_map = orig_map.reversed()\n\n    pitch.draw(ax = ax)\n    bin_statistic = pitch.bin_statistic(xT_transform.x, xT_transform.y, statistic='count', bins=(16, 12))\n    bin_statistic['statistic'] = xT_grid.to_numpy()\n    pt = pitch.heatmap(bin_statistic, ax = ax, cmap = reversed_map, edgecolor = 'black', linewidth = 0.3)\n    pitch.label_heatmap(bin_statistic, color='black', fontsize=7, ax = ax, ha='center', va='center', zorder = 2)\n\n\n    # Arrow \n    arrow_ax = fig.add_axes([0.30, 0.20, 0.35, 0.3]) # X, Y, width, height\n\n    arrow_ax.arrow(0.45, 0.1, 0.30, 0, head_width=0.03, head_length=0.03, linewidth=4, \n               color='darkgrey', length_includes_head=True)\n    arrow_ax.set_ylim(0, 1)\n    arrow_ax.set_xlim(0, 1)\n    arrow_ax.set_axis_off()\n    arrow_ax.annotate('Direction of Play', xy = (0.42, 0.02), fontsize = 10)\n\n\n    # Colorbar\n    ax_cbar = fig.add_axes((0.95, 0.3, 0.03, 0.4))\n    fig.colorbar(pt, cax = ax_cbar).set_label(label = '$s_{x, y}$, probability of shooting', size=10)\n\n    #\n    plt.show()\n\n\n\n\nA5.4 Scoring Probability\n\n\nCode\ndef plot_score_probs():\n\n    # import probability of scoring as .csv file\n    xT_grid = pd.DataFrame(score_probs.round(decimals = 2))\n\n    # transform xT grid into a shap\n    xT_transform = np.zeros(shape = (192, 3))\n    count = 0\n    for i, y in xT_grid.iterrows():\n        for j, x in xT_grid.iteritems():\n            xT_transform[count, :] = np.array([i, j, xT_grid.iloc[int(i), int(j)]])\n            count = count + 1\n    xT_transform = pd.DataFrame(xT_transform)\n    xT_transform.reset_index(drop = True, inplace = True)\n    xT_transform.columns = ['x', 'y', 'value']\n\n\n    # Canvas\n    fig, ax = plt.subplots(figsize = (8, 8))\n\n    # Heatmap\n    pitch = Pitch(pitch_type='wyscout', line_zorder=1,\n                  pitch_color='white', line_color='black', linewidth = 0.5)\n    \n    # getting the original colormap using cm.get_cmap() function\n    orig_map=plt.cm.get_cmap('summer')\n  \n    # reversing the original colormap using reversed() function\n    reversed_map = orig_map.reversed()\n\n    pitch.draw(ax = ax)\n    bin_statistic = pitch.bin_statistic(xT_transform.x, xT_transform.y, statistic='count', bins=(16, 12))\n    bin_statistic['statistic'] = xT_grid.to_numpy()\n    pt = pitch.heatmap(bin_statistic, ax = ax, cmap = reversed_map, edgecolor = '#C3D2A3')\n    pitch.label_heatmap(bin_statistic, color='black', fontsize=7, ax = ax, ha='center', va='center', zorder = 2)\n\n\n    # Arrow \n    arrow_ax = fig.add_axes([0.30, 0.20, 0.35, 0.3]) # X, Y, width, height\n\n    arrow_ax.arrow(0.45, 0.1, 0.30, 0, head_width=0.03, head_length=0.03, linewidth=4, \n               color='darkgrey', length_includes_head=True)\n    arrow_ax.set_ylim(0, 1)\n    arrow_ax.set_xlim(0, 1)\n    arrow_ax.set_axis_off()\n    arrow_ax.annotate('Direction of Play', xy = (0.42, 0.02), fontsize = 10)\n\n\n    # Colorbar\n    ax_cbar = fig.add_axes((0.95, 0.3, 0.03, 0.4))\n    fig.colorbar(pt, cax = ax_cbar).set_label(label = '$xG_{x, y}$, probability of scoring', size=10)\n\n    #\n    plt.show()\n\n\n\n\nA5.5 xT values for Bundesliga Players\n\n\nCode\ndef plot_bundesliga():\n\n    # import Bundesliga xT results\n    bl10 = pd.read_csv(\"bundesliga/top10_players.csv\").sort_values(by = 'xt_per_90', ascending = True)\n    bly10 = pd.read_csv(\"bundesliga/top10_young_players.csv\").sort_values(by = 'xt_per_90', ascending = True)\n\n    # check how colormap looks\n    cm.get_cmap('Blues', 4)\n\n    # For LinearSegmented use (no 'colors' attribute):\n    colors = cm.get_cmap('Greens', 10)\n\n    fig, ax = plt.subplots(nrows = 1, ncols = 2, figsize = (4, 4))\n\n    ax[0].grid(color='black', ls = '-.', lw = 0.25, axis = \"x\")\n    ax[0].barh(bl10[\"nickname\"], bl10[\"xt_per_90\"], height = 0.3,\n           color = colors(range(10)), edgecolor = \"black\", zorder = 2, alpha = 0.7) \n\n    font = {'family': 'monospace',\n            'weight': 'normal',\n            'size': 12,\n            }\n\n    font2 = {'family': 'monospace',\n            'weight': 'normal',\n            'size': 10,\n            }\n\n    ax[0].set_ylabel(\"Player\", fontdict = font2)\n    ax[0].tick_params(axis='both', which='major', labelsize = 8)\n    ax[0].set_xlabel(\"xT per 90\", fontdict = font2)\n    ax[0].set_title(\"Top 10 Players\", loc = \"left\", pad = 10, fontdict = font)\n    ax[0].spines[['top', 'right']].set_visible(False)\n\n    #############################################################################################\n    #############################################################################################\n\n    colors = cm.get_cmap('Reds', 10)\n\n    ax[1].grid(color='black', ls = '-.', lw = 0.25, axis = \"x\")\n    ax[1].barh(bly10[\"nickname\"], bly10[\"xt_per_90\"], height = 0.3,\n           color = colors(range(10)), edgecolor = \"black\", zorder = 2, alpha = 0.7) \n\n    ax[1].set_ylabel(\"Player\", fontdict = font2)\n    ax[1].tick_params(axis='both', which='major', labelsize = 8)\n    ax[1].set_xlabel(\"xT per 90\", fontdict = font2)\n    ax[1].set_title(\"Top 10 Young Players\", loc = \"left\", pad = 10, fontdict = font)\n    ax[1].spines[['top', 'right']].set_visible(False)\n\n\n\n    # set the spacing between subplots\n    plt.subplots_adjust(left = 0.1,\n                        bottom = 1.3, \n                        right = 2, \n                        top = 2, \n                        wspace = 0.65, \n                        hspace = 0.5)\n\n    font3 = {'family': 'monospace',\n            'weight': 'bold',\n            'size': 14\n            }\n\n    font4 = {'family': 'monospace',\n            'style': 'italic',\n            'size': 8,\n            }\n\n    fig.suptitle('xT per 90 for Bundesliga Players | 2017/2018 Season', x = 0.842, y = 2.133, fontproperties = font3)\n    fig.text(x = 1.55, y = 1.15, s = \"Only young players aged <= 21 are included.\", fontdict = font4)\n    fig.text(x = 1.55, y = 1.12, s = \"All players played at least 900 minutes.\", fontdict = font4)\n\n\n    plt.show()\n\n\n\n\nA5.6 xT values for EPL Players\n\n\nCode\ndef plot_epl():\n    \n    # import EPL xT results\n    epl10 = pd.read_csv(\"epl/top10_players.csv\").sort_values(by = 'xt_per_90', ascending = True)\n    eply10 = pd.read_csv(\"epl/top10_young_players.csv\").sort_values(by = 'xt_per_90', ascending = True)\n\n    # check how colormap looks\n    cm.get_cmap('Blues', 4)\n\n    # For LinearSegmented use (no 'colors' attribute):\n    colors = cm.get_cmap('Blues', 10)\n\n    fig, ax = plt.subplots(nrows = 1, ncols = 2, figsize = (4, 4))\n\n    ax[0].grid(color='black', ls = '-.', lw = 0.25, axis = \"x\")\n    ax[0].barh(epl10[\"nickname\"], epl10[\"xt_per_90\"], height = 0.3,\n           color = colors(range(10)), edgecolor = \"black\", zorder = 2, alpha = 0.7) \n\n    font = {'family': 'monospace',\n            'weight': 'normal',\n            'size': 12,\n            }\n\n    font2 = {'family': 'monospace',\n            'weight': 'normal',\n            'size': 10,\n            }\n\n    ax[0].set_xlabel(\"xT per 90\", fontdict = font2)\n    ax[0].set_ylabel(\"Player\", fontdict = font2)\n    ax[0].tick_params(axis='both', which='major', labelsize = 8)\n    ax[0].set_title(\"Top 10 Players\", loc = \"left\", pad = 10, fontdict = font)\n    ax[0].spines[['top', 'right']].set_visible(False)\n\n    #############################################################################################\n    #############################################################################################\n\n    colors = cm.get_cmap('Oranges', 10)\n\n    ax[1].grid(color='black', ls = '-.', lw = 0.25, axis = \"x\")\n    ax[1].barh(eply10[\"nickname\"], eply10[\"xt_per_90\"], height = 0.3,\n           color = colors(range(10)), edgecolor = \"black\", zorder = 2, alpha = 0.7) \n\n    ax[1].set_xlabel(\"xT per 90\", fontdict = font2)\n    ax[1].set_ylabel(\"Player\", fontdict = font2)\n    ax[1].tick_params(axis='both', which='major', labelsize = 8)\n    ax[1].set_title(\"Top 10 Young Players\", loc = \"left\", pad = 10, fontdict = font)\n    ax[1].spines[['top', 'right']].set_visible(False)\n\n\n\n    # set the spacing between subplots\n    plt.subplots_adjust(left = 0.1,\n                        bottom = 1.3, \n                        right = 2, \n                        top = 2, \n                        wspace = 0.65, \n                        hspace = 0.5)\n\n    font3 = {'family': 'monospace',\n            'weight': 'bold',\n            'size': 14\n            }\n\n    font4 = {'family': 'monospace',\n            'style': 'italic',\n            'size': 8,\n            }\n\n    fig.suptitle('xT per 90 for EPL Players | 2017/2018 Season', x = 0.74, y = 2.133, fontproperties = font3)\n    fig.text(x = 1.6, y = 1.15, s = \"Only young players aged <= 21 are included.\", fontdict = font4)\n    fig.text(x = 1.6, y = 1.12, s = \"All players played at least 900 minutes.\", fontdict = font4)\n\n\n    plt.show()\n\n\n\n\nA5.7 xT values for LaLiga Players\n\n\nCode\ndef plot_laliga():\n    \n    # import LaLiga xT results\n    ll10 = pd.read_csv(\"laliga/top10_players.csv\").sort_values(by = 'xt_per_90', ascending = True)\n    lly10 = pd.read_csv(\"laliga/top10_young_players.csv\").sort_values(by = 'xt_per_90', ascending = True)\n\n    # For LinearSegmented use (no 'colors' attribute):\n    colors = cm.get_cmap('Greys', 10)\n\n    fig, ax = plt.subplots(nrows = 1, ncols = 2, figsize = (4, 4))\n\n    ax[0].grid(color='black', ls = '-.', lw = 0.25, axis = \"x\")\n    ax[0].barh(ll10[\"nickname\"], ll10[\"xt_per_90\"], height = 0.3,\n           color = colors(range(10)), edgecolor = \"black\", zorder = 2, alpha = 0.7) \n\n    font = {'family': 'monospace',\n            'weight': 'normal',\n            'size': 12,\n            }\n\n    font2 = {'family': 'monospace',\n            'weight': 'normal',\n            'size': 10,\n            }\n\n    ax[0].set_ylabel(\"Player\", fontdict = font2)\n    ax[0].set_xlabel(\"xT per 90\", fontdict = font2)\n    ax[0].tick_params(axis='both', which='major', labelsize = 8)\n    ax[0].set_title(\"Top 10 Players\", loc = \"left\", pad = 10, fontdict = font)\n    ax[0].spines[['top', 'right']].set_visible(False)\n\n    #############################################################################################\n    #############################################################################################\n\n    colors = cm.get_cmap('RdPu', 10)\n\n    ax[1].grid(color='black', ls = '-.', lw = 0.25, axis = \"x\")\n    ax[1].barh(lly10[\"nickname\"], lly10[\"xt_per_90\"], height = 0.3,\n           color = colors(range(10)), edgecolor = \"black\", zorder = 2, alpha = 0.7) \n\n    ax[1].set_ylabel(\"Player\", fontdict = font2)\n    ax[1].set_xlabel(\"xT per 90\", fontdict = font2)\n    ax[1].tick_params(axis='both', which='major', labelsize = 8)\n    ax[1].set_title(\"Top 10 Young Players\", loc = \"left\", pad = 10, fontdict = font)\n    ax[1].spines[['top', 'right']].set_visible(False)\n\n\n\n    # set the spacing between subplots\n    plt.subplots_adjust(left = 0.1,\n                        bottom = 1.3, \n                        right = 2, \n                        top = 2, \n                        wspace = 0.65, \n                        hspace = 0.5)\n\n    font3 = {'family': 'monospace',\n            'weight': 'bold',\n            'size': 14\n            }\n\n    font4 = {'family': 'monospace',\n            'style': 'italic',\n            'size': 8,\n            }\n\n    fig.suptitle('xT per 90 for LaLiga Players | 2017/2018 Season', x = 0.79, y = 2.133, fontproperties = font3)\n    fig.text(x = 1.55, y = 1.15, s = \"Only young players aged <= 21 are included.\", fontdict = font4)\n    fig.text(x = 1.55, y = 1.12, s = \"All players played at least 900 minutes.\", fontdict = font4)\n\n\n    plt.show()\n\n\n\n\nA5.8 xT values for Ligue 1 Players\n\n\nCode\ndef plot_ligue1():\n    \n    # import Ligue 1 xT results\n    l10 = pd.read_csv(\"ligue1/top10_players.csv\").sort_values(by = 'xt_per_90', ascending = True)\n    ly10 = pd.read_csv(\"ligue1/top10_young_players.csv\").sort_values(by = 'xt_per_90', ascending = True)\n\n    # For LinearSegmented use (no 'colors' attribute):\n    colors = cm.get_cmap('GnBu', 10)\n\n    fig, ax = plt.subplots(nrows = 1, ncols = 2, figsize = (4, 4))\n\n    ax[0].grid(color='black', ls = '-.', lw = 0.25, axis = \"x\")\n    ax[0].barh(l10[\"nickname\"], l10[\"xt_per_90\"], height = 0.3,\n           color = colors(range(10)), edgecolor = \"black\", zorder = 2, alpha = 0.7) \n\n    font = {'family': 'monospace',\n            'weight': 'normal',\n            'size': 12,\n            }\n\n    font2 = {'family': 'monospace',\n            'weight': 'normal',\n            'size': 10,\n            }\n\n    ax[0].set_ylabel(\"Player\", fontdict = font2)\n    ax[0].set_xlabel(\"xT per 90\", fontdict = font2)\n    ax[0].tick_params(axis='both', which='major', labelsize = 8)\n    ax[0].set_title(\"Top 10 Players\", loc = \"left\", pad = 10, fontdict = font)\n    ax[0].spines[['top', 'right']].set_visible(False)\n\n    #############################################################################################\n    #############################################################################################\n\n    colors = cm.get_cmap('PuRd', 10)\n\n    ax[1].grid(color='black', ls = '-.', lw = 0.25, axis = \"x\")\n    ax[1].barh(ly10[\"nickname\"], ly10[\"xt_per_90\"], height = 0.3,\n           color = colors(range(10)), edgecolor = \"black\", zorder = 2, alpha = 0.7) \n\n    ax[1].set_ylabel(\"Player\", fontdict = font2)\n    ax[1].set_xlabel(\"xT per 90\", fontdict = font2)\n    ax[1].tick_params(axis='both', which='major', labelsize = 8)\n    ax[1].set_title(\"Top 10 Young Players\", loc = \"left\", pad = 10, fontdict = font)\n    ax[1].spines[['top', 'right']].set_visible(False)\n\n\n\n    # set the spacing between subplots\n    plt.subplots_adjust(left = 0.1,\n                        bottom = 1.3, \n                        right = 2, \n                        top = 2, \n                        wspace = 0.65, \n                        hspace = 0.5)\n\n    font3 = {'family': 'monospace',\n            'weight': 'bold',\n            'size': 14\n            }\n\n    font4 = {'family': 'monospace',\n            'style': 'italic',\n            'size': 8,\n            }\n\n    fig.suptitle('xT per 90 for Ligue 1 Players | 2017/2018 Season', x = 0.8, y = 2.133, fontproperties = font3)\n    fig.text(x = 1.6, y = 1.15, s = \"Only young players aged <= 21 are included.\", fontdict = font4)\n    fig.text(x = 1.6, y = 1.12, s = \"All players played at least 900 minutes.\", fontdict = font4)\n\n\n    plt.show()"
  },
  {
    "objectID": "data_preprocessing.html",
    "href": "data_preprocessing.html",
    "title": "Part 1 | Data Preprocessing",
    "section": "",
    "text": "In addition to pandas, the following packages need to be imported:\n\nimport os\nimport ast\nimport numpy as np \nimport pandas as pd\n\nThere are different publicly available soccer match event datasets. For this model, I decided to work with female soccer match event data due to a high granularity of event descriptions provided by the vendor, Statsbomb. This granularity can help me in building a sophisticated model and design features that can increase its accuracy. To learn more about other available datasets released by Statsbomb, feel free to visit this link.\nTo extract data from Statsbomb API, different methodologies are available. I prefer to work with socceraction library that allows me to extract data in a convenient pandas.DataFrame format.\n\n# import wyscout public match event data loader from socceraction library\nfrom socceraction.data.statsbomb import StatsBombLoader \n\n# remove credentials warning from statsbomb api since we work with public data \nimport warnings\nwarnings.filterwarnings(\"ignore\", message=\"credentials were not supplied. open data access only\")\n\n# load public wyscout data\nstbm_data = StatsBombLoader()\n\n# read available competitions and filter out only female related ones\ncompetitions = stbm_data.competitions()\nfemale_comps = competitions.loc[competitions['competition_gender'] == 'female', :].reset_index(drop = True)\nfemale_comps\n\n\n\n\n\n  \n    \n      \n      season_id\n      competition_id\n      competition_name\n      country_name\n      competition_gender\n      season_name\n    \n  \n  \n    \n      0\n      90\n      37\n      FA Women's Super League\n      England\n      female\n      2020/2021\n    \n    \n      1\n      42\n      37\n      FA Women's Super League\n      England\n      female\n      2019/2020\n    \n    \n      2\n      4\n      37\n      FA Women's Super League\n      England\n      female\n      2018/2019\n    \n    \n      3\n      3\n      49\n      NWSL\n      United States of America\n      female\n      2018\n    \n    \n      4\n      106\n      53\n      UEFA Women's Euro\n      Europe\n      female\n      2022\n    \n    \n      5\n      30\n      72\n      Women's World Cup\n      International\n      female\n      2019\n    \n  \n\n\n\n\nAs can be seen, data is available for four different female soccer competitions. Three seasons of FA Women’s Super League, one season of NWSL and two competitions involving national teams, UEFA Women’s Euro 2022 and Women’s World Cup 2019.\nBelow code illustrates steps required to read event data on each game from the aforementioned competitions and save it as .csv file. I also save all .csv files into a single all_events dataframe. Later, this will allow me to extract an event of interest from all games at once.\n\n# names of folders to save files\ndir_names = ['FAWSL_2021', 'FAWSL_1920', 'FAWSL_1819', 'NWSL', 'EURO_2022', 'WC_2019']\n\n# for each competition save all games as .csv files\nfor i, j in female_comps.loc[:, ['season_id', 'competition_id']].iterrows():\n    # j[0] = season_id, j[1] = competition_id\n    games = stbm_data.games(j[1], j[0]).loc[:, 'game_id']\n    for k in games:\n        events = stbm_data.events(k)\n        events.to_csv(f'.data/{dir_names[i]}/games/{k}.csv', index = False)\n\n# concatenate all events into a single data frame\nall_events = pd.DataFrame()\nfor i in dir_names:\n    games = os.listdir(f'.data/{i}/games')\n    for j in games:\n        df = pd.read_csv(f'.data/{i}/games/{j}')\n        all_events = pd.concat([all_events, df])\n\n# rest index and save as .csv file\nall_events = all_events.reset_index(drop = True)\nall_events.to_csv('.data/all_events.csv', index = False)\n\n\nall_events.head(3)\n\n\n\n\n\n  \n    \n      \n      game_id\n      event_id\n      period_id\n      team_id\n      player_id\n      type_id\n      type_name\n      index\n      timestamp\n      minute\n      ...\n      team_name\n      duration\n      extra\n      related_events\n      player_name\n      position_id\n      position_name\n      location\n      under_pressure\n      counterpress\n    \n  \n  \n    \n      0\n      3764230\n      3f5dde74-d91b-44ea-9a1f-88e84da555ab\n      1\n      749\n      NaN\n      35\n      Starting XI\n      1\n      1900-01-01 00:00:00.000\n      0\n      ...\n      Tottenham Hotspur Women\n      0.0\n      {'tactics': {'formation': 4231, 'lineup': [{'p...\n      []\n      NaN\n      NaN\n      NaN\n      NaN\n      False\n      False\n    \n    \n      1\n      3764230\n      e4fefe61-4e08-47e0-be4d-2276388e6eb4\n      1\n      972\n      NaN\n      35\n      Starting XI\n      2\n      1900-01-01 00:00:00.000\n      0\n      ...\n      West Ham United LFC\n      0.0\n      {'tactics': {'formation': 433, 'lineup': [{'pl...\n      []\n      NaN\n      NaN\n      NaN\n      NaN\n      False\n      False\n    \n    \n      2\n      3764230\n      ff9a99d3-3efd-45c2-8736-a8a93dd02638\n      1\n      972\n      NaN\n      18\n      Half Start\n      3\n      1900-01-01 00:00:00.000\n      0\n      ...\n      West Ham United LFC\n      0.0\n      {}\n      ['5fb7026c-83aa-4490-96b1-a55825c4dcb8']\n      NaN\n      NaN\n      NaN\n      NaN\n      False\n      False\n    \n  \n\n3 rows × 26 columns\n\n\n\nThere is a wide range of data describing each event. Since xG model evaluates the probability of a shot to result in a goal, I can filter only shot events, extract columns of interest to this event and test these columns after preprocessing in the model building phase.\n\n# list all features to select ones required for xG model\nall_events.columns\n\nIndex(['game_id', 'event_id', 'period_id', 'team_id', 'player_id', 'type_id',\n       'type_name', 'index', 'timestamp', 'minute', 'second', 'possession',\n       'possession_team_id', 'possession_team_name', 'play_pattern_id',\n       'play_pattern_name', 'team_name', 'duration', 'extra', 'related_events',\n       'player_name', 'position_id', 'position_name', 'location',\n       'under_pressure', 'counterpress'],\n      dtype='object')\n\n\n\n# filter event type_name = 'Shot' and leave only required columns \nshots = all_events.loc[all_events['type_name'] == 'Shot', \n                       ['minute', 'player_name', 'team_name', 'type_name', 'play_pattern_name', \n                        'position_name', 'location', 'under_pressure', 'extra']].reset_index(drop = True)\n\nThe following columns are dropped due to their irrelevance to the context of the model: ‘game_id’, ‘event_id’, ‘period_id’, ‘team_id’, ‘player_id’, ‘type_id’, ‘index’, ‘timestamp’, ‘minute’, ‘second’, ‘possession’, ‘possession_team_id’, ‘possession_team_name’, ‘play_pattern_id’, ‘duration’, ‘related_events’, ‘position_id’.\nAs you can see, a majority of these events are id identifiers. For example, play_pattern_id is ommited while play_pattern is left in the dataframe. The rest of the columns include time- or possession-related information which will not make any use in our case.\nOne of the most important columns, as we will see later, is location of the shot. I extract required (x, y) coordinates from a given list and save them as separate columns for a simpler use case during feature engineering phase.\nIt is important to note that when dataframes are saved as .csv files, all of them are converted into a raw string format. Thus, when reading these dataframes, one needs to convert columns containing specific datatypes into a python readable format. For that, I use ast package and, specifically, ast.literal_eval() function. This allows me to convert a string of a list into a python readable list object.\n\n# unlist location column into (x, y) and remove it\nshots.loc[:, 'location'] = shots.loc[:, 'location'].apply(ast.literal_eval)\nshots.loc[:, 'x_start'] = shots.loc[:, 'location'].apply(lambda x: x[0])\nshots.loc[:, 'y_start'] = shots.loc[:, 'location'].apply(lambda x: x[1])\nshots = shots.drop(columns = 'location')\n\n\nshots.head()\n\n\n\n\n\n  \n    \n      \n      minute\n      player_name\n      team_name\n      type_name\n      play_pattern_name\n      position_name\n      under_pressure\n      extra\n      x_start\n      y_start\n    \n  \n  \n    \n      0\n      7\n      Lucy Quinn\n      Tottenham Hotspur Women\n      Shot\n      Regular Play\n      Right Wing\n      False\n      {'shot': {'statsbomb_xg': 0.013642391, 'end_lo...\n      95.9\n      58.9\n    \n    \n      1\n      10\n      Rianna Dean\n      Tottenham Hotspur Women\n      Shot\n      From Free Kick\n      Center Forward\n      False\n      {'shot': {'statsbomb_xg': 0.04084396, 'end_loc...\n      106.1\n      54.3\n    \n    \n      2\n      11\n      Angela Addison\n      Tottenham Hotspur Women\n      Shot\n      From Free Kick\n      Left Wing\n      True\n      {'shot': {'statsbomb_xg': 0.13687119, 'end_loc...\n      110.0\n      28.2\n    \n    \n      3\n      13\n      Kit Graham\n      Tottenham Hotspur Women\n      Shot\n      From Throw In\n      Center Attacking Midfield\n      False\n      {'shot': {'statsbomb_xg': 0.12462413, 'end_loc...\n      113.2\n      40.4\n    \n    \n      4\n      16\n      Kit Graham\n      Tottenham Hotspur Women\n      Shot\n      From Counter\n      Center Attacking Midfield\n      False\n      {'shot': {'statsbomb_xg': 0.02380701, 'end_loc...\n      95.2\n      39.8\n    \n  \n\n\n\n\nThe column named extra contains additional information describing shot event. This is where we can observe that Statsbomb provides a high level of event data granularity. For example, below you can see that for each shot, the location of all players, specifically opposing team’s goalkeeper, within a visible video frame is recorded. In addition, there is data about body_part with which a shot was implemented, technique (which as per event data description guide is “name of the technique used for this shot”), open_goal which is a boolean variable that describes if a shot was taken with an open goal, follows_dribble which is a boolean variable that describes if a taken shot was followed by dribble or not and first_time which is a boolean variable that describes if a shot was taken with the first touch or not. Due to vendor specifications, only boolean variables with True state appear in extra column; thus, I have to specify False state for all other cases explicitly.\nAs you can see, variables follows_dribble and open_goal are missing from below instance of extra column due to False state.\n\nshots.loc[:, 'extra'][148]\n\n{'shot': {'open_goal': True,\n  'statsbomb_xg': 0.84770715,\n  'end_location': [120.0, 39.0, 0.9],\n  'body_part': {'id': 40, 'name': 'Right Foot'},\n  'type': {'id': 87, 'name': 'Open Play'},\n  'outcome': {'id': 97, 'name': 'Goal'},\n  'first_time': True,\n  'technique': {'id': 91, 'name': 'Half Volley'},\n  'freeze_frame': [{'location': [111.4, 38.3],\n    'player': {'id': 4647, 'name': 'So-Yun Ji'},\n    'position': {'id': 13, 'name': 'Right Center Midfield'},\n    'teammate': True},\n   {'location': [108.8, 42.9],\n    'player': {'id': 4636, 'name': 'Maria Thorisdottir'},\n    'position': {'id': 2, 'name': 'Right Back'},\n    'teammate': True},\n   {'location': [110.1, 53.6],\n    'player': {'id': 4961, 'name': 'Samantha May Kerr'},\n    'position': {'id': 21, 'name': 'Left Wing'},\n    'teammate': True},\n   {'location': [106.3, 51.4],\n    'player': {'id': 10108, 'name': 'Pernille Mosegaard Harder'},\n    'position': {'id': 17, 'name': 'Right Wing'},\n    'teammate': True},\n   {'location': [110.8, 35.7],\n    'player': {'id': 46738, 'name': 'Emma Bissell'},\n    'position': {'id': 16, 'name': 'Left Midfield'},\n    'teammate': False},\n   {'location': [110.1, 39.8],\n    'player': {'id': 36801, 'name': 'Aimee Palmer'},\n    'position': {'id': 13, 'name': 'Right Center Midfield'},\n    'teammate': False},\n   {'location': [116.1, 42.8],\n    'player': {'id': 16376, 'name': 'Sophie Baggaley'},\n    'position': {'id': 1, 'name': 'Goalkeeper'},\n    'teammate': False},\n   {'location': [116.1, 45.7],\n    'player': {'id': 16381, 'name': 'Gemma Evans'},\n    'position': {'id': 5, 'name': 'Left Center Back'},\n    'teammate': False},\n   {'location': [110.5, 46.1],\n    'player': {'id': 15618, 'name': 'Jasmine Matthews'},\n    'position': {'id': 3, 'name': 'Right Center Back'},\n    'teammate': False},\n   {'location': [111.2, 50.0],\n    'player': {'id': 24922, 'name': 'Florence Allen'},\n    'position': {'id': 2, 'name': 'Right Back'},\n    'teammate': False},\n   {'location': [114.5, 49.3],\n    'player': {'id': 24239, 'name': 'Jemma Elizabeth Purfield'},\n    'position': {'id': 6, 'name': 'Left Back'},\n    'teammate': False}]}}\n\n\nIn addition to above-mentioned data, I also extract contenxtual information from extra column. These are type, statsbomb_xg and outcome variables. The last one is important for knowing if a taken shot results in a goal or not. The variable type will help me to filter out only open play situations and discard outlying conditions where a shot is taken directly from corner, free-kick, penalty or kick-off. These are situations that can largely skew performance of the proposed xG model, and it is better to build a separate model that focuses only on them.\nI unpack extra column that consists of dictionaries, extract required data and save it as separate columns in the dataframe.\n\n# convert 'extra' column to dict readable format using ast.literal_eval\nshots_extra = shots.loc[:, 'extra'].apply(ast.literal_eval).reset_index(drop = True)\n\n# specify which features to extract from 'extra' column\nkeys = ['follows_dribble', 'first_time', 'open_goal', 'statsbomb_xg', \\\n        'type', 'technique', 'body_part', 'outcome']\n# save selected features in a dataframe\nextra_features = pd.DataFrame(np.nan, columns = keys, index = range(shots.shape[0]))\nfor i, j in shots_extra.iteritems():\n    for k in list(j['shot'].keys()):\n        if k in ['type', 'technique', 'body_part', 'outcome']:\n            extra_features.loc[i, k] = j['shot'][k]['name']\n        elif k in keys:\n            extra_features.loc[i, k] = j['shot'][k]\n        elif k == 'freeze_frame':\n            extra_features.loc[i, k] = [{'freeze_frame':j['shot'][k]}]\n        elif (k == 'end_location'):\n            extra_features.loc[i, 'end_loc'] = [{'end_loc':j['shot'][k]}]\n            \n        \n# fill NAs with boolean = False (technically, these are not NAs but just undeclared False values)\nextra_features = extra_features.fillna(value = False)\n# transform columns with boolean values into integers \nextra_features.loc[:, ['follows_dribble', 'first_time', 'open_goal']] = \\\nextra_features.loc[:, ['follows_dribble', 'first_time', 'open_goal']].astype(int)\nshots.loc[:, 'under_pressure'] = shots.loc[:, 'under_pressure'].astype(int)\n\n\nshots = pd.concat([shots.drop(columns = ['extra', 'type_name']), extra_features], axis = 1)\nshots.head()\n\n\n\n\n\n  \n    \n      \n      minute\n      player_name\n      team_name\n      play_pattern_name\n      position_name\n      under_pressure\n      x_start\n      y_start\n      follows_dribble\n      first_time\n      open_goal\n      statsbomb_xg\n      type\n      technique\n      body_part\n      outcome\n      end_loc\n      freeze_frame\n    \n  \n  \n    \n      0\n      7\n      Lucy Quinn\n      Tottenham Hotspur Women\n      Regular Play\n      Right Wing\n      0\n      95.9\n      58.9\n      0\n      0\n      0\n      0.013642\n      Open Play\n      Normal\n      Left Foot\n      Saved\n      [{'end_loc': [116.7, 44.9, 1.2]}]\n      [{'freeze_frame': [{'location': [119.6, 42.3],...\n    \n    \n      1\n      10\n      Rianna Dean\n      Tottenham Hotspur Women\n      From Free Kick\n      Center Forward\n      0\n      106.1\n      54.3\n      0\n      0\n      0\n      0.040844\n      Open Play\n      Normal\n      Right Foot\n      Off T\n      [{'end_loc': [120.0, 41.6, 4.2]}]\n      [{'freeze_frame': [{'location': [118.8, 43.2],...\n    \n    \n      2\n      11\n      Angela Addison\n      Tottenham Hotspur Women\n      From Free Kick\n      Left Wing\n      1\n      110.0\n      28.2\n      0\n      0\n      0\n      0.136871\n      Open Play\n      Normal\n      Left Foot\n      Saved\n      [{'end_loc': [117.6, 36.7, 0.4]}]\n      [{'freeze_frame': [{'location': [111.3, 39.8],...\n    \n    \n      3\n      13\n      Kit Graham\n      Tottenham Hotspur Women\n      From Throw In\n      Center Attacking Midfield\n      0\n      113.2\n      40.4\n      0\n      0\n      0\n      0.124624\n      Open Play\n      Normal\n      Head\n      Post\n      [{'end_loc': [120.0, 37.9, 2.9]}]\n      [{'freeze_frame': [{'location': [105.8, 46.6],...\n    \n    \n      4\n      16\n      Kit Graham\n      Tottenham Hotspur Women\n      From Counter\n      Center Attacking Midfield\n      0\n      95.2\n      39.8\n      0\n      0\n      0\n      0.023807\n      Open Play\n      Normal\n      Left Foot\n      Post\n      [{'end_loc': [120.0, 37.3, 2.9]}]\n      [{'freeze_frame': [{'location': [97.8, 49.4], ...\n    \n  \n\n\n\n\nAlso, I would like to extract opposing team’s goalkeeper location during each executed shot. These coordinates are contained in freeze_frame column.\n\n# write a custom function to unpack dictionaries within freeze_frame column\ndef ff_unpacking(players):\n    players = players[0]['freeze_frame']\n    for i in players:\n        if i['position']['name'] == 'Goalkeeper' and i['teammate'] == False:\n            gk_loc = i['location']\n            return gk_loc\n\nshots.loc[:, 'gk_loc'] = shots.loc[:, 'freeze_frame'].apply(lambda x: ff_unpacking(x))\n\n# Note that there are 42 None instances where goalkeeper location was incorrectly labeled.\nshots = shots.loc[~shots.loc[:, 'gk_loc'].isnull(), :].reset_index(drop = True)\n\n# save (x, y) coordinates of a goalkeeper as separate columns\nshots.loc[:, 'gk_loc_x'] = shots.loc[:, 'gk_loc'].apply(lambda x: x[0])\nshots.loc[:, 'gk_loc_y'] = shots.loc[:, 'gk_loc'].apply(lambda x: x[1])\n\nFinally, I save my shots dataframe as .csv file.\n\nshots.to_csv('.data/shots.csv', index = False)\n\nThis is the end of preprocessing stage for data that will be used in the proposed xG model. Now, we can move on to the model building phase that will focus on exploratory data analysis, feature engineering and model selection."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Farid Musayev",
    "section": "",
    "text": "I am interested in:\nStatistical Machine Learning, Deep Learning and Software Development."
  },
  {
    "objectID": "p1.html",
    "href": "p1.html",
    "title": "Expected Goals Model",
    "section": "",
    "text": "Soccer is a low-scoring game. Thus, it appears difficult to evaluate performance of teams by looking only at the number of scored and conceded goals. In comparison to goals, teams usually execute a much higher number of shots. However, not all of these shots are of the same quality. In other words, different shots may have different probabilities of being scored. These probabilities may depend on many different parameters. In this project, I implement Expected Goals Model that computes how likely is a given shot to result in a goal.\nProject repository is available here."
  },
  {
    "objectID": "p1.html#implementation",
    "href": "p1.html#implementation",
    "title": "Expected Goals Model",
    "section": "Implementation",
    "text": "Implementation\nThe project consists of the following parts:\n\nPart 1 | Data Preprocessing\nIn this section, I demonstrate how to extract data from an external resource, filter out only required competitions, specify the columns of interest and bring them into a desirable format.\nPart 2 | Building Model\nThis part mainly focuses on the exploratory data analysis, design of new features, statistical analysis of existing features, splitting and transforming data, hyperparameter tuning and model selection."
  },
  {
    "objectID": "p3.html",
    "href": "p3.html",
    "title": "Scientific Visualization",
    "section": "",
    "text": "Gibbs Sampling Convergence\nThis is a visualization of two parameters, variance and mean, which were sampled from their respective conditional posterior distributions until convergence. The upper plots show the trajectories of sampled Markov Chains. The lower plots show the number of iterations required to reach convergence for each parameter. This plot was designed using ggplot2.\nCode is available here.\n\nThis plot was created in collaboration with Kristina Levina.\n\n\nMCMC Convergence of Parameters\nIn this visualization, Markov chain Monte Carlo (MCMC) algorithm is used to draw parameters of Poisson regression from a multivariate posterior distribution. After approximately 250 iterations, the parameters start to converge. This plot was designed using ggplot2.\nCode is available here.\n\nThis plot was created in collaboration with Kristina Levina."
  },
  {
    "objectID": "building_model.html",
    "href": "building_model.html",
    "title": "Part 2 | Building Model",
    "section": "",
    "text": "In this part, the following packages need to be imported:\n\n\nCode\n# Preprocessing\nimport ast\nimport pandas as pd\nimport numpy as np\n\n# Visualization\nimport matplotlib.pyplot as plt\nfrom matplotlib import cm\nfrom matplotlib.lines import Line2D\nfrom mplsoccer import Pitch, VerticalPitch\nimport seaborn as sns\n%config InlineBackend.figure_formats = ['svg']\n\n# Data Splitting and Transformation\nfrom sklearn.model_selection import train_test_split, RandomizedSearchCV\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\n\n# Statistical Distributions\nfrom scipy.stats import uniform, randint\n\n# Modeling\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier \nimport statsmodels.formula.api as smf\n\n# Model Evaluation\nfrom sklearn.metrics import roc_auc_score, brier_score_loss"
  },
  {
    "objectID": "building_model.html#exploratory-data-analysis",
    "href": "building_model.html#exploratory-data-analysis",
    "title": "Part 2 | Building Model",
    "section": "Exploratory Data Analysis",
    "text": "Exploratory Data Analysis\nFirstly, I read the preprocessed .csv data file and convert all required columns to python readable object types.\n\n\nCode\n# read shots.csv file \nshots = pd.read_csv('.data/shots.csv')\nshots.loc[:, 'freeze_frame'] = shots.loc[:, 'freeze_frame'].apply(ast.literal_eval)\nshots.loc[:, 'gk_loc'] = shots.loc[:, 'gk_loc'].apply(ast.literal_eval)\nshots.loc[:, 'end_loc'] = shots.loc[:, 'end_loc'].apply(ast.literal_eval)\n\n\nPrediction of a goal outcome in soccer is a binary classification task { 0 - No goal ; 1 - Goal }. However, the key point is that, in xG model, we are not dealing with hard classes but rather trying to make a probabilistic prediction for a shot outcome. In comparison with hard classes, probabilistic outputs allow to describe the quality of a shot since not all shots are equally probable to be scored. In other words, given a shot, how likely it is to result in a goal. This is what the xG value estimates for a given shot.\nThe code snippet below shows that there are different outcome types for a given shot such as Saved, Off target, shot that hit Post, Blocked, way off target Wayward shot, etc. To build a binary probabilistic classifier, it is necessary to define predictions as hard classes. Here, I convert each value of outcome_type column to 1 for Goal scenario or 0 for the rest of scenarios.\n\n\nCode\nshots.loc[:, 'outcome'].unique()\n\n\narray(['Saved', 'Off T', 'Post', 'Goal', 'Blocked', 'Wayward',\n       'Saved Off Target', 'Saved to Post'], dtype=object)\n\n\n\n\nCode\n# rename existing 'outcome' column to 'outcome_type' \nshots = shots.rename(columns = {'outcome': 'outcome_type'})\n# save binary results into a newly created 'outcome' column\nshots.loc[:, 'outcome'] = shots.loc[:, 'outcome_type'].apply(lambda x: 1 if x == 'Goal' else 0)\nshots.loc[:, 'outcome']\n\n\n0        0\n1        0\n2        0\n3        0\n4        0\n        ..\n11038    0\n11039    0\n11040    0\n11041    0\n11042    0\nName: outcome, Length: 11043, dtype: int64\n\n\nNow, let us analyze the types of available shots and their frequencies. From Figure 1, it can be seen that our dataframe contains data on 11043 shots. Below you can see that 1165 of them resulted in a goal.\n\n\nCode\n# Data preparation\nshot_types = pd.DataFrame(shots.loc[:, 'outcome_type'].value_counts()).reset_index()\nshot_types.columns = ['outcome_type', 'n']\nshot_types = shot_types.sort_values(by = 'n', ascending = True)\n\n# Canvas\nfig, ax = plt.subplots(figsize = (5, 5))\n\n# grid specs\nax.grid(color = 'black', ls = '-.', lw = 0.25, axis = \"x\")\n\n# Main plot\npl = ax.barh(shot_types[\"outcome_type\"], shot_types[\"n\"], height = 0.6, label = 'n',\n       color = 'skyblue', edgecolor = \"black\", zorder = 2, alpha = 0.7) \n\n# Barplot labels\nax.bar_label(pl, padding = 5, label_type='edge')\n\n# Labels and titles\nax.set_ylabel(\"Outcome Type\", fontsize = 10)\nax.set_xlabel(\"# of instances\", fontsize = 10)\nax.tick_params(axis = 'both', which = 'major', labelsize = 10)\nax.spines[['top', 'right']].set_visible(False)\n\nplt.show()\n\n\n\n\n\nFigure 1: Distribution of shot outcomes across female soccer competitions.\n\n\n\n\nTo sum up, we can see that a majority of shots are off target, blocked or saved. Since only 1165 out of 11043 shots are goals, we can conclude that our data is imbalanced. This will affect our choice of model evaluation metric in the model selection phase.\nNext, we can visualize the location of all shots.\n\n\nCode\n# Canvas\npitch = Pitch(pitch_type = 'statsbomb')  \nfig, ax = pitch.draw(figsize=(6, 8))\n\n# Plot\nsns.scatterplot(data = shots, x = 'x_start', y = 'y_start', ax = ax,\n                hue = 'outcome', palette = 'seismic', edgecolor = 'black', alpha = 0.4)\n\n# legend design\ncustom = [Line2D([], [], marker = '.', color = 'b', linestyle = 'None'),\n          Line2D([], [], marker = '.', color = 'r', linestyle = 'None')]\n\nplt.legend(custom, ['No Goal', 'Goal'], bbox_to_anchor = (0.05, 0.21))\n\n# Arrow design\narrow_ax = fig.add_axes([0.28, 0.22, 0.35, 0.3]) # X, Y, width, height\n\narrow_ax.arrow(0.45, 0.1, 0.30, 0, head_width = 0.03, head_length = 0.03, linewidth = 4, \n           color = 'darkgrey', length_includes_head = True)\narrow_ax.set_ylim(0, 1)\narrow_ax.set_xlim(0, 1)\narrow_ax.set_axis_off()\narrow_ax.annotate('Direction of Play', xy = (0.42, 0.02), fontsize = 10)\n\n\nplt.show()\n\n\n\n\n\nFigure 2: Distribution of shots according to their coordinates.\n\n\n\n\nA majority of shots is made in the central block of the final third area. In addition, there are several outlying shots made from a central area and flang positions. On the right flang, some of outliers even resulted in a goal."
  },
  {
    "objectID": "building_model.html#feature-engineering",
    "href": "building_model.html#feature-engineering",
    "title": "Part 2 | Building Model",
    "section": "Feature Engineering",
    "text": "Feature Engineering\nWhen it comes to the analysis of a shot made by a player, one can even intuitively predict whether that shot will have a decent outcome or not. In practice, two major factors drive this intuition and can be actually quantified. These are distance to a goal and angle under which a shot is taken.\n\n\nCode\n# Pitch design\npitch = VerticalPitch(pitch_type = 'statsbomb',\n                      half = True, \n                      pad_left = 0, pad_right = 0, pad_top = 0, pad_bottom = 0.15)  \n# Canvas\nfig, ax = pitch.draw(nrows = 1, ncols = 3, figsize = (8, 10))\n\n# Data preparation\nx = np.array([100, 120, 105, 120, 110, 120]).reshape(3, 2)\ny = np.array([20, 40, 50, 40, 40, 40]).reshape(3, 2)\nfor i in range(3):\n    # Plot\n    pitch.goal_angle(x[i][0], y[i][0], ax = ax[i], alpha = 0.4, color = 'skyblue')\n    pitch.lines(x[i][0], y[i][0], x[i][1], y[i][1], ax = ax[i], linewidth = 1)\n\n\nplt.show()\n\n\n\n\n\nFigure 3: Different distances to a goal (solid line) and angles (shaded area) for a given shot.\n\n\n\n\n\nDistance and Angle Features\nTo demonstrate an impact of distance and angle features on the probability of a shot to result in a goal, I evaluate these features from a given (x, y) coordinate of each shot and build a simple logistic regression that makes probabilitistic predictions.\nTo evaluate the distance to a goal, I calculate the Euclidean distance between (x, y) coordinate of a shot and the goal centerline. Since I work with Statsbomb data, I use their pitch dimensions, which are [0, 120] on the x axis and [0, 80] on the y axis. Thus, the goal centerline coordinates are (120, 40).\nBelow you can see my implementation:\n\n# Distance Feature calculation\n\n# define goal center for 'statsbomb'\ngoal_center = np.array([120, 40])\n\n# calculate distance between a shot coordinate and goal centerline coordinate\nshots['distance'] = np.sqrt((shots['x_start'] - goal_center[0])**2 + (shots['y_start'] - goal_center[1])**2)\nshots['distance'] = shots['distance'].round(decimals = 2)\n\nNext, I calculate the angle of a shot. The task breaks down to finding the angle between two sides of a triangle given that all lengths (a, b, c) of the triangle are known.\nBelow you can see my implementation:\n\n# Angle Feature calculation\n\n# transform (x, y) coordinates from percentiles to field length coordinates (105 meters x 68 meters)\nx = shots['x_start'] * 105/120\ny = shots['y_start'] * 68/80 \n\n# Use trigonometric formula to find an angle between two sides (a,b) of a triangle where the third side (c) \n# is a goal line of length 7.32 meters.\na = np.sqrt((x - 105)**2 + (y - 30.34)**2) # length between right post and (x, y) shot coordinate\nb = np.sqrt((x - 105)**2 + (y - 37.66)**2) # length between left post and (x, y) shot coordinate\nc = 7.32 # goal line length in meters\ncos_alpha = (a**2 + b**2 - c**2)/(2*a*b)\ncos_alpha = np.round(cos_alpha, decimals = 4)\n\n# remember to leave angle in radians (if you want to transfer to degree multiply cos_alpha by 180/pi)\nshots['angle'] = np.arccos(cos_alpha)\n\nNow, I would like to demonstrate how both of these features impact the probability of scoring.\nI run a simple logistic regression that includes only these features (distance, angle) and obtain probabilisitc predictions for each shot. Then, I plot both of these features against the probabilistic predictions to visualize the relationship. The objective is to illustrate the relationship between the features and the probability of scoring.\n\n\nCode\n# Prepare features and labels from available data\nX = shots.loc[:, ['distance', 'angle']]\ny = shots.loc[:, 'outcome']\n\n# Fit Logistic Regression Model\nclassifier = LogisticRegression()\nclassifier.fit(X, y)\n\n# make predictions\npredictions = classifier.predict_proba(X)[:, 1]\n\n\n# Canvas\nfig, ax = plt.subplots(nrows = 1, ncols = 2, figsize = (10, 4))\n\n# Distance plot design\n\n# grid\nax[0].grid(color = 'black', ls = '-.', lw = 0.25, axis = \"both\")\n\n# plot\nax[0].scatter(X['distance'], predictions, color = 'gray', s = 0.5, alpha = 0.4)\nax[0].set_xlabel('Distance')\nax[0].set_ylabel('Probability of scoring')\n\n# axis adjustments\nax[0].set_ylim(0, 0.8)\nax[0].set_xlim(0, 90)\nax[0].yaxis.get_major_ticks()[0].label1.set_visible(False)\nax[0].tick_params(length = 0)\n\n############################################\n\n# Angle plot design\n\n# grid\nax[1].grid(color = 'black', ls = '-.', lw = 0.25, axis = \"both\")\n\n# plot\nax[1].scatter(X['angle'], predictions, color = 'orange', s = 0.5, alpha = 0.4)\nax[1].set_xlabel('Angle')\nax[1].set_ylabel('Probability of scoring')\n\n# axis adjustments\nax[1].set_ylim(0, 0.8)\nax[1].set_xlim(0, 3.5)\nax[1].yaxis.get_major_ticks()[0].label1.set_visible(False)\nax[1].tick_params(length = 0)\n\nax[0].text(x = 44, y = -0.2, s = 'a)', fontsize = 12)\nax[1].text(x = 1.72, y = -0.2, s = 'b)', fontsize = 12)\n\n\nplt.show()\n\n\n\n\n\nFigure 4: Probability of scoring decreases with increasing distance (a) and increases with increasing angle (b).\n\n\n\n\nAs can be seen from a) part of Figure 4, the inprobability of scoring (or you can also call it xG value) decreases exponentially with increasing distance. On the contrast, the probability of scoring increases linearly with angle.\nIn both plots of Figure 4, there are densely populated parts that can be analyzed in a slightly different way. From these areas a majority of shots is executed. When analyzing Figure 5, we can observe that most of the shots are executed within the distance range from 5 to 30 m. Most of the angles of the executed shots are distributed within the angle range from 0 to 60 degrees (or from 0 to 1 radians, respectively).\n\n\nCode\n# Canvas\nfig, ax = plt.subplots(nrows = 1, ncols = 2, figsize = (10, 4))\n\n# Distance density plot design\nax[0].grid(color = 'black', ls = '-.', lw = 0.25, axis = \"both\")\nsns.kdeplot(x = 'distance', data = shots, ax = ax[0], color = 'gray')\nax[0].set_xlabel('Distance')\nax[0].set_ylim(0, 0.045)\nax[0].set_yticks(np.arange(0, 0.045, 0.01))\nax[0].set_xlim(-10, 100)\n\n\n# Angle density plot design\nax[1].grid(color = 'black', ls = '-.', lw = 0.25, axis = \"both\")\nsns.kdeplot(x = 'angle', data = shots, ax = ax[1], color = 'orange')\nax[1].set_xlabel('Angle')\nax[1].set_ylim(0, 2.8)\n\nax[0].text(x = 44, y = -0.01, s = 'a)', fontsize = 12)\nax[1].text(x = 1.5, y = -0.63, s = 'b)', fontsize = 12)\n\n\nplt.show()\n\n\n\n\n\nFigure 5: Distribution of distances (a) and angles (b) for all executed shots."
  },
  {
    "objectID": "building_model.html#statistical-analysis",
    "href": "building_model.html#statistical-analysis",
    "title": "Part 2 | Building Model",
    "section": "Statistical Analysis",
    "text": "Statistical Analysis\nAll features are included into the logistic regression model to analyze their statistical signficance. The objective is to analyze p-values for each of the features and determine which of these values are weakly associated with the response.\n\n\nCode\n# Data Preparation\nX = shots.loc[:, ['play_pattern_name','under_pressure', 'distance', 'angle', 'gk_loc_x', 'gk_loc_y',\n                   'follows_dribble', 'first_time', 'open_goal', 'technique', 'body_part']]\ny = shots.loc[:, 'outcome']\n\ndf_train = pd.concat([X, y], axis = 1).reset_index(drop = True)\n\n# run model\nlogreg_model = smf.logit(\n    formula = \"outcome ~ distance + angle + under_pressure + gk_loc_y + gk_loc_x + \\\n    body_part + open_goal + play_pattern_name\",\n                         data = df_train).fit()\n\n# Extract p-values\npd.DataFrame(logreg_model.pvalues, columns = ['p-value']).round(decimals = 3)\n\n\nOptimization terminated successfully.\n         Current function value: 0.284721\n         Iterations 8\n\n\n\n\n\n\n  \n    \n      \n      p-value\n    \n  \n  \n    \n      Intercept\n      0.000\n    \n    \n      body_part[T.Left Foot]\n      0.000\n    \n    \n      body_part[T.Other]\n      0.642\n    \n    \n      body_part[T.Right Foot]\n      0.000\n    \n    \n      play_pattern_name[T.From Counter]\n      0.001\n    \n    \n      play_pattern_name[T.From Free Kick]\n      0.000\n    \n    \n      play_pattern_name[T.From Goal Kick]\n      0.000\n    \n    \n      play_pattern_name[T.From Keeper]\n      0.203\n    \n    \n      play_pattern_name[T.From Kick Off]\n      0.239\n    \n    \n      play_pattern_name[T.From Throw In]\n      0.001\n    \n    \n      play_pattern_name[T.Other]\n      0.252\n    \n    \n      play_pattern_name[T.Regular Play]\n      0.000\n    \n    \n      distance\n      0.000\n    \n    \n      angle\n      0.000\n    \n    \n      under_pressure\n      0.056\n    \n    \n      gk_loc_y\n      0.431\n    \n    \n      gk_loc_x\n      0.000\n    \n    \n      open_goal\n      0.000\n    \n  \n\n\n\n\nThere are several categorical variables with very high p-values. These are body_part[T.Other], play_pattern_name[T.From Keeper], play_pattern_name[T.From Kick Off], play_pattern_name[T.Other] and gk_loc_y. Let us analyze these features and decide if we can drop them from the model.\nFirst, play_pattern_name column describes different types of play during which a shot was executed. Below code snippet shows that there are 9 types of play in total.\n\n\nCode\nshots.loc[:, 'play_pattern_name'].unique()\n\n\narray(['Regular Play', 'From Free Kick', 'From Throw In', 'From Counter',\n       'From Corner', 'From Keeper', 'From Goal Kick', 'From Kick Off',\n       'Other'], dtype=object)\n\n\n\n\nCode\n# Data preparation for barplot 1\nplay_types = pd.DataFrame(shots.loc[:, 'play_pattern_name'].value_counts()).reset_index()\nplay_types.columns = ['play_pattern_name', 'n']\nplay_types = play_types.sort_values(by = 'n', ascending = True)\n\n# Data preparation for barplot 2\nbody_part = pd.DataFrame(shots.loc[:, 'body_part'].value_counts()).reset_index()\nbody_part.columns = ['body_part', 'n']\nbody_part = body_part.sort_values(by = 'n', ascending = True)\n\n# Canvas\nfig, ax = plt.subplots(nrows = 1, ncols = 2, figsize = (4, 4))\n\n# Grid specs\nax[0].grid(color = 'black', ls = '-.', lw = 0.25, axis = \"x\")\n\n# Main plot\npl = ax[0].barh(play_types[\"play_pattern_name\"], play_types[\"n\"], height = 0.6, label = 'n',\n       color = 'skyblue', edgecolor = \"black\", zorder = 2, alpha = 0.7) \n\n# Barplot labels\nax[0].bar_label(pl, padding = 5, label_type='edge', fontsize = 8)\n\n# Labels and titles\nax[0].set_ylabel(\"Type of Play\", fontsize = 10)\nax[0].set_xlabel(\"# of instances\", fontsize = 10)\nax[0].tick_params(axis = 'both', which = 'major', labelsize = 8)\nax[0].spines[['top', 'right']].set_visible(False)\n\n#############################################################################\n\n# Grid specs\nax[1].grid(color = 'black', ls = '-.', lw = 0.25, axis = \"x\")\n\n# Main plot\npl2 = ax[1].barh(body_part[\"body_part\"], body_part[\"n\"], height = 0.4, label = 'n',\n       color = 'red', edgecolor = \"black\", zorder = 2, alpha = 0.7) \n\n# Barplot labels\nax[1].bar_label(pl2, padding = 5, label_type='edge', fontsize = 8)\n\n# Labels and titles\nax[1].set_ylabel(\"Body part\", fontsize = 10)\nax[1].set_xlabel(\"# of instances\", fontsize = 10)\nax[1].tick_params(axis = 'both', which = 'major', labelsize = 8)\nax[1].spines[['top', 'right']].set_visible(False)\n\n\n# Set the spacing parameters between subplots\nplt.subplots_adjust(left = 0.1,\n                    bottom = 1.3, \n                    right = 2, \n                    top = 2, \n                    wspace = 0.65, \n                    hspace = 0.5)\n\nplt.show()\n\n\n\n\n\nFigure 6: Distribution of shots in different types of play (left) and implemented with different parts of the body (right).\n\n\n\n\nFeatures play_pattern_name[T.From Keeper], play_pattern_name[T.From Kick Off], play_pattern_name[T.Other] that received high p-values are actually very rare events and can be considered as outliers in the model. There are very few situations in which attack starting from goalkeeper or from a kick-off can result in a goal. From Figure 6, it can be seen that, in total, 300 shots were executed in types of play: ‘From Keeper’, ‘From Kick Off’ and ‘Other’.\n\n\nCode\nprint(np.sum(shots.loc[shots['play_pattern_name'] == 'From Keeper', 'outcome']), \n     'goals were scored when attack was initiated by a goalkeeper.',)\n\n\n13 goals were scored when attack was initiated by a goalkeeper.\n\n\n\n\nCode\nprint(np.sum(shots.loc[shots['play_pattern_name'] == 'From Kick Off', 'outcome']),\n      'goals were scored when attack was initiated from a kick-off.')\n\n\n10 goals were scored when attack was initiated from a kick-off.\n\n\n\n\nCode\nprint(np.sum(shots.loc[shots['play_pattern_name'] == 'Other', 'outcome']),\n      'goals were scored when attack was initiated in other scenarios.')\n\n\n7 goals were scored when attack was initiated in other scenarios.\n\n\nIn total, only 30 out of these 300 shots were scored.\nA similar pattern can be observed when analyzing body_part categorical column and body_part[T.Other] feature that received a high p-value. Out of 11043 shots available in the dataset, only 30 shots were executed with a body part other than foot or head.\n\n\nCode\nprint('Only', np.sum(shots.loc[shots['body_part'] == 'Other', 'outcome']),\n      'goals out of 30 shots were scored with a body part other than foot or head.')\n\n\nOnly 6 goals out of 30 shots were scored with a body part other than foot or head.\n\n\nTo sum up both of these scenarios, only 330 shots and 36 goals fall into these outlying conditions. This is a relatively small sample size in comparison to the available data; thus, I exclude these data points from analysis.\n\n\nCode\nshots = shots.loc[~((shots['play_pattern_name'] == 'Other') | (shots['play_pattern_name'] == 'From Keeper' ) \n| (shots['play_pattern_name'] == 'From Kick Off') | (shots['body_part'] == 'Other')),  :]\n\n\nFinally, there is one more column gk_loc_y which also has a high p-value. This column together with gk_loc_x describe the location of the opposing team’s goalkeeper during an executed shot. Naturally, a goalkeeper standing on the goalline can move differently but in most of the cases along the goalline. This means that the y coordinate should change much more frequently than the x coordinate. However, the y coordinate is less significant in the model than the x coordinate. As of now, I will leave both of these features in the dataset."
  },
  {
    "objectID": "building_model.html#transforming-and-splitting-data",
    "href": "building_model.html#transforming-and-splitting-data",
    "title": "Part 2 | Building Model",
    "section": "Transforming and Splitting Data",
    "text": "Transforming and Splitting Data\nOne-hot encoding transformation is applied to all categorical variables present in the dataset. These are body_part, technique and play_pattern_name. Note that variables under_pressure, follows_dribble, first_time and open_goal are already transformed into 0/1 boolean variables (False/True); thus, they do not need any additional preprocessing. In addition, features distance, angle, gk_loc_x and gk_loc_y are standardized.\n\n\nCode\n# Prepare features and labels from available data\nX = shots.loc[:, ['play_pattern_name','under_pressure', 'distance', 'angle', 'gk_loc_x', 'gk_loc_y',\n                   'follows_dribble', 'first_time', 'open_goal', 'technique', 'body_part']]\ny = shots.loc[:, 'outcome']\n\n# split data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n\n\nIn the next section, model selection will be implemented using RandomizedSearchCV. Thus, the dataset is splitted into X_train, y_train, X_test, y_test where k-fold cross validation will be applied on X_train, y_train to find optimal parameters for each type of model. Finally, each model will be run on X_test, y_test to evaluate its performance on new data.\n\n\nCode\n# Build a column transformer\ncolumn_trans = ColumnTransformer(\n    [('encode_bodyparts', OneHotEncoder(dtype='int'), ['play_pattern_name', 'technique', 'body_part']),\n    ('std_coords', StandardScaler(), ['distance', 'angle', 'gk_loc_x', 'gk_loc_y'])],\n    remainder = 'passthrough', verbose_feature_names_out = True)\n\n# Transform feature columns\nX_train = column_trans.fit_transform(X_train)\nX_test = column_trans.transform(X_test)"
  },
  {
    "objectID": "building_model.html#model-selection",
    "href": "building_model.html#model-selection",
    "title": "Part 2 | Building Model",
    "section": "Model Selection",
    "text": "Model Selection\nThree different classifiers were run and evaluated on the given dataset. These are Logistic Regression, Gradient Boosting and Random Forest. Since I am interested in predicting probabilistic outputs, the aim is to achieve the highest accuracy of the probabilistic predictions. Thus, I use Brier score as an evaluation metric in RandomizedSearchCV. In addition, I evaluate ROC-AUC score for each model with its best parameters. However, ROC-AUC is mainly used here as a supportive metric to illustrate the performance in comparison with a random guess.\n\nLogistic Regression\n\n\nCode\n# Model\nmodel = LogisticRegression(solver = 'saga', max_iter = 200, random_state = 42)\n\n# Hyperparameters\nparameters = dict(C = uniform(loc = 0, scale = 4), \n                  penalty = ['l2', 'l1'])\n\n# Classifier\nclassifier = RandomizedSearchCV(model, parameters, random_state = 42, \n                                cv = 10, scoring = 'neg_brier_score')\nclassifier.fit(X_train, y_train)\nprint('Optimal parameters are:\\n', classifier.best_params_)\n\n# Evaluate on test data\npredictions = classifier.predict_proba(X_test)[:, 1]\nprint('Brier score = ', brier_score_loss(y_test, predictions))\nprint('ROC-AUC = ', roc_auc_score(y_test, predictions))\n\n\nOptimal parameters are:\n {'C': 1.49816047538945, 'penalty': 'l2'}\nBrier score =  0.0778472702630083\nROC-AUC =  0.7810976028573392\n\n\n\n\nGradient Boosting\n\n\nCode\n# Model\nmodel = GradientBoostingClassifier(random_state = 42)\n\n# Hyperparameters\nparameters = dict(learning_rate = uniform(loc = 0.03, scale = 0.035),\n                  n_estimators = randint(100, 800),\n                  loss = ['exponential', 'deviance'])\n# Classifier\nclassifier = RandomizedSearchCV(model, parameters, random_state = 42, \n                                cv = 10, scoring = 'neg_brier_score')\nclassifier.fit(X_train, y_train)\nprint('Optimal parameters are:\\n', classifier.best_params_)\n\n# Evaluate on test data\npredictions = classifier.predict_proba(X_test)[:, 1]\nprint('Brier score = ', brier_score_loss(y_test, predictions))\nprint('ROC-AUC = ', roc_auc_score(y_test, predictions))\n\n\nOptimal parameters are:\n {'learning_rate': 0.055619787963399184, 'loss': 'exponential', 'n_estimators': 120}\nBrier score =  0.07818749793751041\nROC-AUC =  0.7805726452954971\n\n\n\n\nRandom Forest\n\n\nCode\n# Model\nmodel = RandomForestClassifier(random_state = 42)\n\n# Hyperparameters\nparameters = dict(max_depth = randint(5, 50),\n                  criterion = ['entropy', 'gini'],\n                  min_samples_split = randint(2, 50))\n\n# Classifier\nclassifier = RandomizedSearchCV(model, parameters, random_state = 42, \n                                cv = 10, scoring = 'neg_brier_score')\nclassifier.fit(X_train, y_train)\nprint('Optimal parameters are:\\n', classifier.best_params_)\n\n# Evaluate on test data\npredictions = classifier.predict_proba(X_test)[:, 1]\nprint('Brier score = ', brier_score_loss(y_test, predictions))\nprint('ROC-AUC = ', roc_auc_score(y_test, predictions))\n\n\nOptimal parameters are:\n {'criterion': 'entropy', 'max_depth': 12, 'min_samples_split': 22}\nBrier score =  0.07892679615459904\nROC-AUC =  0.7761693797650938\n\n\nTo sum up, when comparing Brier scores for each classifier, it can be seen that Logistic Regression outperforms Gradient Boosting and Random Forest by a small margin. In addition, Logistic Regression demonstrates the highest ROC-AUC value (0.781). This value is well above 0.5, which confirms that the classifier performs much better than a random guess."
  },
  {
    "objectID": "building_model.html#future-improvements",
    "href": "building_model.html#future-improvements",
    "title": "Part 2 | Building Model",
    "section": "Future Improvements",
    "text": "Future Improvements\nThe model illustrates a good performance. However, there are always areas for improvement that I would like to briefly outline:\n\nAdd more extensive analysis in model selection and evaluation phase.\nPerform more thorough analysis of opposing team’s goalkeeper coordinates.\nAnalyze how discarded outliers may affect model performance.\nAnalyze the correlation between features using different techniques such as point biserial correlation and chi square test of association.\nUse the location of opposing team’s defenders to construct additional features."
  }
]