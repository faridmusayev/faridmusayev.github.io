[
  {
    "objectID": "p2.html",
    "href": "p2.html",
    "title": "Data Visualization",
    "section": "",
    "text": "In this visualization, I make a gridplot of xG values conceded and scored by each team against all other teams in Allsvenskan (Swedish Top Football League) during season 2021. Since this is a gridplot, one can obtain only a general performance overview for each team. This gridplot was designed using object-oriented plotting in matplotlib.\nCode is available here.\n\nTo view this plot in a high resolution, please follow this link."
  },
  {
    "objectID": "p2.html#gibbs-sampling-convergence",
    "href": "p2.html#gibbs-sampling-convergence",
    "title": "Data Visualization",
    "section": "Gibbs Sampling Convergence",
    "text": "Gibbs Sampling Convergence\nThis is a visualization of two parameters, variance and mean, which were sampled from their respective conditional posterior distributions until convergence. The upper plots show the trajectories of sampled Markov Chains. The lower plots show the number of iterations required to reach convergence for each parameter. This plot was designed using ggplot2.\nCode is available here.\n\nThis plot was created in collaboration with Kristina Levina."
  },
  {
    "objectID": "p2.html#mcmc-convergence-of-parameters",
    "href": "p2.html#mcmc-convergence-of-parameters",
    "title": "Data Visualization",
    "section": "MCMC Convergence of Parameters",
    "text": "MCMC Convergence of Parameters\nIn this visualization, Markov chain Monte Carlo (MCMC) algorithm is used to draw parameters of Poisson regression from a multivariate posterior distribution. After approximately 250 iterations, the parameters start to converge. This plot was designed using ggplot2.\nCode is available here.\n\nThis plot was created in collaboration with Kristina Levina."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Farid Musayev",
    "section": "",
    "text": "I am interested in:\nstatistical data analysis, machine learning and data visualization."
  },
  {
    "objectID": "xG_for_against_subplots.html#package-prerequisites",
    "href": "xG_for_against_subplots.html#package-prerequisites",
    "title": "Allsvenskan 2021",
    "section": "Package Prerequisites",
    "text": "Package Prerequisites\n\n# import required libraries\nimport os\nimport json\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib_inline\nfrom matplotlib.font_manager import FontProperties\nfrom matplotlib import image\nfrom matplotlib.offsetbox import OffsetImage, AnnotationBbox"
  },
  {
    "objectID": "xG_for_against_subplots.html#data-preparation",
    "href": "xG_for_against_subplots.html#data-preparation",
    "title": "Allsvenskan 2021",
    "section": "Data Preparation",
    "text": "Data Preparation\n\n# export required data frame\ndf = pd.read_csv(\"data/refined/merged_match_results.csv\")\n\n# find for each team xG For and xG against\nall_xg_for = pd.concat([df['home_np_xg'], df['away_np_xg']])\nall_xg_against = pd.concat([df['away_np_xg'], df['home_np_xg']])"
  },
  {
    "objectID": "xG_for_against_subplots.html#plot-extras",
    "href": "xG_for_against_subplots.html#plot-extras",
    "title": "Allsvenskan 2021",
    "section": "Plot Extras",
    "text": "Plot Extras\n\n# define a dictionary of colors for each team\nteam_color = {'Malmö FF':['skyblue', 'white'], \n              'AIK':['darkblue', 'yellow'],  \n              'Djurgården':['skyblue', 'darkblue'], \n              'IF Elfsborg':['yellow', 'black'], \n              'Hammarby':['white', 'darkgreen'],\n              'Kalmar FF':['red', '#EBCD57'], \n              'IFK Norrköping FK':['white', 'blue'], \n              'IFK Göteborg':['blue', '#EBCD57'], \n              'Mjällby AIF':['#FCDF51', 'black'],\n              'Varbergs BoIS FC':['#53B663', 'black'], \n              'IK Sirius FK':['blue', 'black'], \n              'BK Häcken':['black', '#FFF275'], \n              'Degerfors IF':['white', 'red'],\n              'Halmstad':['#6B91EB', 'black'], \n              'Örebro':['white', 'black'], \n              'Östersund':['red', 'black']}\n\n# create a list of teams, according to their ranking, to iterate over\nteam_ranks = ['Malmö FF', 'AIK', 'Djurgården', 'IF Elfsborg', 'Hammarby',\n'Kalmar FF', 'IFK Norrköping FK', 'IFK Göteborg', 'Mjällby AIF',\n'Varbergs BoIS FC', 'IK Sirius FK', 'BK Häcken', 'Degerfors IF',\n'Halmstad', 'Örebro', 'Östersund']"
  },
  {
    "objectID": "xG_for_against_subplots.html#design",
    "href": "xG_for_against_subplots.html#design",
    "title": "Allsvenskan 2021",
    "section": "Design",
    "text": "Design\n\n# list of club logo paths to iterate over \nfiles = os.listdir('images/club_logos/')\n\nfig, ax = plt.subplots(nrows = 4, ncols = 4, figsize = (18, 18), \n                            gridspec_kw={'hspace': 0.44})\n\n# figure face color equal to axis face color\nfig.set_facecolor(\"#FFF7EE\")\n\n# Font Properties:\n# (x, y) axis labels\nlabel_fps = FontProperties(family = 'Maven Pro', size = 28, weight = 'medium')\n# each plot title\nax_fps = FontProperties(family = 'Maven Pro', size = 20, weight = 'medium')\n# figure title\nfig_fps = FontProperties(family = 'Maven Pro', size = 45, weight = 'medium')\n# data source:\nds_fps = FontProperties(family = 'Maven Pro', size = 16)\n\n\nind = 0\nfor i in range(4):\n    for j in range(4):\n        \n        # grid settings\n        ax[i, j].grid(color='#62625F', ls = '-.', lw = 0.25, zorder = 0)\n\n        # face color of axis\n        ax[i, j].set_facecolor(\"#FFF7EE\")\n        \n        # plot dashed line \n        x = np.array([0, 7])\n        y = np.array([0, 7])\n        ax[i, j].plot(x, y, c = 'darkgray', ls = '--', lw = 1, zorder = 3)\n\n        # data filtering steps: \n        # 1.take a team from a list and filter data frame 'team_df'\n        team_df = df[(df['home'] == team_ranks[ind]) | (df['away'] == team_ranks[ind])]\n        \n        # 2. filter non-penalty xG for\n        team_df[team_df['home'] == team_ranks[ind]]['home_np_xg']\n        team_df[team_df['away'] == team_ranks[ind]]['away_np_xg']\n        xg_for = pd.concat([team_df[team_df['home'] == team_ranks[ind]]['home_np_xg'],\n                 team_df[team_df['away'] == team_ranks[ind]]['away_np_xg']])\n        \n        # 3. filter non-penalty xG against\n        team_df[team_df['home'] == team_ranks[ind]]['away_np_xg']\n        team_df[team_df['away'] == team_ranks[ind]]['home_np_xg']\n        xg_against = pd.concat([team_df[team_df['home'] == team_ranks[ind]]['away_np_xg'], \n                     team_df[team_df['away'] == team_ranks[ind]]['home_np_xg']])\n\n        \n        ax[i, j].scatter(all_xg_against, all_xg_for, c = 'gray', alpha = 0.3, s = 50, edgecolor = 'none', zorder = 3)\n        ax[i, j].scatter(xg_against, xg_for, s = 100, c = team_color[team_ranks[ind]][0], \n                         edgecolor = team_color[team_ranks[ind]][1], zorder = 3)\n\n        # set limit for x and y axis\n        ax[i, j].set_xlim(0, 7)\n        ax[i, j].set_ylim(0, 7)\n        ax[i, j].set_xticks(np.arange(0, 8, 1))\n        ax[i, j].set_xticks(np.arange(0, 8, 1))\n        ax[i, j].set_aspect('equal')\n        \n        # remove tick lines from both axis\n        ax[i, j].tick_params(length = 0)\n\n        # remove '0' on y-axis\n        ax[i, j].yaxis.get_major_ticks()[0].label1.set_visible(False)\n        \n        # remove top and right spines\n        ax[i, j].spines[['top', 'right']].set_visible(False)\n        \n        # spines color\n        spines_color = '#62625F'\n        ax[i, j].spines['bottom'].set_color(spines_color)\n        ax[i, j].spines['top'].set_color(spines_color) \n        ax[i, j].spines['right'].set_color(spines_color)\n        ax[i, j].spines['left'].set_color(spines_color)\n        \n        # font dictionary\n        font3 = {'family': 'monospace', 'weight': 'bold', 'size': 14}\n        \n        # title for each plot\n        ax[i, j].set_title(team_ranks[ind], loc = 'left', x = 0.225, y = 1.08, fontproperties = ax_fps)\n        \n        # remove topmost and rightmost gridlines:\n        # retrieve all x and y gridlines\n        y_gridlines = ax[i, j].get_ygridlines()\n        x_gridlines = ax[i, j].get_xgridlines()\n        # select topmost and rightmost and remove them\n        y_last = y_gridlines[-1]\n        y_last.set_visible(False)\n        x_last = x_gridlines[-1]\n        x_last.set_visible(False)\n        \n        # club logo settings:\n        club_logo = image.imread(\"images/club_logos/\" + files[ind])\n        # add into image box\n        club_logo = OffsetImage(club_logo, zoom = 0.04)\n        # assign axis to image box\n        club_logo.image.axes = ax[i, j]\n        # set coordinates\n        ab = AnnotationBbox(club_logo, xy = (0.065, 1.16), xycoords = 'axes fraction', frameon = False)\n        # add to axis\n        ax[i, j].add_artist(ab)\n        \n        # update index for a list of teams\n        ind = ind + 1\n        \n\n# league logo settings:\nleague_img = image.imread(\"images/other_logos/allsvenskan_logo.png\")\nleague_logo = fig.add_axes([0.88, 0.88, 0.1, 0.1])\nleague_logo.set_axis_off()\nleague_logo.imshow(league_img, aspect = \"equal\")        \n\n# figure title and labels\nfig.supxlabel('xG Against', fontproperties = label_fps, y = 0.04)\nfig.supylabel('xG For', fontproperties = label_fps, x = 0.1)\nfig.suptitle('ALLSVENSKAN | 2021 SEASON', x = 0.485, y = 0.94, fontproperties = fig_fps)\n\n# annotations and logo for data source\nfig.text(0.01, 0.015, r\"data source:\", fontproperties = ds_fps)\nds_img = image.imread(\"images/other_logos/plm.png\")\nds_logo = fig.add_axes([0.08, 0.001, 0.05, 0.05])\nds_logo.set_axis_off()\nds_logo.imshow(ds_img, aspect = \"equal\") \n\n# author annotations:\nfig.text(0.85, 0.015, r\"author: Farid Musayev\", fontproperties = ds_fps)\n\n# create a space for a title and left/right axis\nfig.subplots_adjust(bottom = 0.085, top = 0.83)\n\nplt.show()\n\n# save figure\nfig.savefig('xg_subplots.png', dpi = 350, transparent = False)\n\n\n\n\nTo view this plot in a high resolution, please follow this link."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Projects",
    "section": "",
    "text": "Expected Goals Model | Data Visualization"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Farid Musayev",
    "section": "",
    "text": "python\n\n\npandas\n\n\n\n\nhow to understand this life ?\n\n\n\n\n\n\nAug 14, 2022\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nmatplotlib\n\n\nsklearn\n\n\n\n\nhow to understand this life ?\n\n\n\n\n\n\nAug 14, 2022\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "building_model.html",
    "href": "building_model.html",
    "title": "Part 2 | Building Model",
    "section": "",
    "text": "In this part, the following packages need to be imported:\n\n\nCode\nimport os\nimport ast\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib import cm\nfrom matplotlib.lines import Line2D\nfrom mplsoccer import Pitch, VerticalPitch\nimport seaborn as sns\n%config InlineBackend.figure_formats = ['svg']"
  },
  {
    "objectID": "building_model.html#exploratory-data-analysis",
    "href": "building_model.html#exploratory-data-analysis",
    "title": "Part 2 | Building Model",
    "section": "Exploratory Data Analysis",
    "text": "Exploratory Data Analysis\nFirstly, I read the preprocessed .csv data file and convert all required columns to python readable object types.\n\n\nCode\n# read shots.csv file \nshots = pd.read_csv('.data/shots.csv')\nshots.loc[:, 'freeze_frame'] = shots.loc[:, 'freeze_frame'].apply(ast.literal_eval)\nshots.loc[:, 'gk_loc'] = shots.loc[:, 'gk_loc'].apply(ast.literal_eval)\nshots.loc[:, 'end_loc'] = shots.loc[:, 'end_loc'].apply(ast.literal_eval)\n\n\nPrediction of a goal outcome in soccer is a binary classification task { 0 - No goal ; 1 - Goal }. However, the key point is that, in xG model, we are not dealing with hard classes but rather trying to make a probabilistic prediction for a shot outcome. In comparison with hard classes, probabilistic outputs allow to describe the quality of a shot since not all shots are equally probable to be scored. In other words, given a shot, how likely it is to result in a goal. This is what the xG value estimates for a given shot.\nThe code snippet below shows that there are different outcome types for a given shot such as Saved, Off target, shot that hit Post, Blocked, way off target Wayward shot, etc. To build a binary probabilistic classifier, it is necessary to define predictions as hard classes. Here, I convert each value of outcome_type column to 1 for Goal scenario or 0 for the rest of scenarios.\n\n\nCode\nshots.loc[:, 'outcome'].unique()\n\n\narray(['Saved', 'Off T', 'Post', 'Goal', 'Blocked', 'Wayward',\n       'Saved Off Target', 'Saved to Post'], dtype=object)\n\n\n\n\nCode\n# rename existing 'outcome' column to 'outcome_type' \nshots = shots.rename(columns = {'outcome': 'outcome_type'})\n# save binary results into a newly created 'outcome' column\nshots.loc[:, 'outcome'] = shots.loc[:, 'outcome_type'].apply(lambda x: 1 if x == 'Goal' else 0)\nshots.loc[:, 'outcome']\n\n\n0        0\n1        0\n2        0\n3        0\n4        0\n        ..\n11038    0\n11039    0\n11040    0\n11041    0\n11042    0\nName: outcome, Length: 11043, dtype: int64\n\n\nNow, let us analyze the types of available shots and their frequencies. From Figure 1, it can be seen that our dataframe contains data on 11043 shots. Below you can see that 1165 of them resulted in a goal.\n\n\nCode\n# Data preparation\nshot_types = pd.DataFrame(shots.loc[:, 'outcome_type'].value_counts()).reset_index()\nshot_types.columns = ['outcome_type', 'n']\nshot_types = shot_types.sort_values(by = 'n', ascending = True)\n\n# Canvas\nfig, ax = plt.subplots(figsize = (5, 5))\n\n# grid specs\nax.grid(color = 'black', ls = '-.', lw = 0.25, axis = \"x\")\n\n# Main plot\npl = ax.barh(shot_types[\"outcome_type\"], shot_types[\"n\"], height = 0.6, label = 'n',\n       color = 'skyblue', edgecolor = \"black\", zorder = 2, alpha = 0.7) \n\n# Barplot labels\nax.bar_label(pl, padding = 5, label_type='edge')\n\n# Labels and titles\nax.set_ylabel(\"Outcome Type\", fontsize = 10)\nax.set_xlabel(\"# of instances\", fontsize = 10)\nax.tick_params(axis = 'both', which = 'major', labelsize = 10)\nax.spines[['top', 'right']].set_visible(False)\n\nplt.show()\n\n\n\n\n\nFigure 1: Distribution of shot outcomes across female soccer competitions.\n\n\n\n\nTo sum up, we can see that a majority of shots are off target, blocked or saved. Since only 1165 out of 11043 shots are goals, we can conclude that our data is imbalanced. This will affect our choice of model evaluation metric in the model selection phase.\nNext, we can visualize the location of all shots.\n\n\nCode\n# Canvas\npitch = Pitch(pitch_type = 'statsbomb')  \nfig, ax = pitch.draw(figsize=(6, 8))\n\n# Plot\nsns.scatterplot(data = shots, x = 'x_start', y = 'y_start', ax = ax,\n                hue = 'outcome', palette = 'seismic', edgecolor = 'black', alpha = 0.4)\n\n# legend design\ncustom = [Line2D([], [], marker = '.', color = 'b', linestyle = 'None'),\n          Line2D([], [], marker = '.', color = 'r', linestyle = 'None')]\n\nplt.legend(custom, ['No Goal', 'Goal'], bbox_to_anchor = (0.05, 0.21))\n\n# Arrow design\narrow_ax = fig.add_axes([0.28, 0.22, 0.35, 0.3]) # X, Y, width, height\n\narrow_ax.arrow(0.45, 0.1, 0.30, 0, head_width = 0.03, head_length = 0.03, linewidth = 4, \n           color = 'darkgrey', length_includes_head = True)\narrow_ax.set_ylim(0, 1)\narrow_ax.set_xlim(0, 1)\narrow_ax.set_axis_off()\narrow_ax.annotate('Direction of Play', xy = (0.42, 0.02), fontsize = 10)\n\n\nplt.show()\n\n\n\n\n\nFigure 2: Distribution of shots according to their coordinates.\n\n\n\n\nA majority of shots is made in the central block of the final third area. In addition, there are several outlying shots made from a central area and flang positions. On the right flang, some of outliers even resulted in a goal."
  },
  {
    "objectID": "building_model.html#feature-engineering",
    "href": "building_model.html#feature-engineering",
    "title": "Part 2 | Building Model",
    "section": "Feature Engineering",
    "text": "Feature Engineering\nWhen it comes to the analysis of a shot made by a player, one can even intuitively predict whether that shot will have a decent outcome or not. In practice, two major factors drive this intuition and can be actually quantified. These are distance to a goal and angle under which a shot is taken.\n\n\nCode\n# Pitch design\npitch = VerticalPitch(pitch_type = 'statsbomb',\n                      half = True, \n                      pad_left = 0, pad_right = 0, pad_top = 0, pad_bottom = 0.15)  \n# Canvas\nfig, ax = pitch.draw(nrows = 1, ncols = 3, figsize = (8, 10))\n\n# Data preparation\nx = np.array([100, 120, 105, 120, 110, 120]).reshape(3, 2)\ny = np.array([20, 40, 50, 40, 40, 40]).reshape(3, 2)\nfor i in range(3):\n    # Plot\n    pitch.goal_angle(x[i][0], y[i][0], ax = ax[i], alpha = 0.4, color = 'skyblue')\n    pitch.lines(x[i][0], y[i][0], x[i][1], y[i][1], ax = ax[i], linewidth = 1)\n\n\nplt.show()\n\n\n\n\n\nFigure 3: Different distances to a goal (solid line) and angles (shaded area) for a given shot.\n\n\n\n\n\nDistance and Angle Features\nTo demonstrate an impact of distance and angle features on the probability of a shot to result in a goal, I evaluate these features from a given (x, y) coordinate of each shot and build a simple logistic regression that makes probabilitistic predictions.\nTo evaluate the distance to a goal, I calculate the Euclidean distance between (x, y) coordinate of a shot and the goal centerline. Since I work with Statsbomb data, I use their pitch dimensions, which are [0, 120] on the x axis and [0, 80] on the y axis. Thus, the goal centerline coordinates are (120, 40).\nBelow you can see my implementation:\n\n# Distance Feature calculation\n\n# define goal center for 'statsbomb'\ngoal_center = np.array([120, 40])\n\n# calculate distance between a shot coordinate and goal centerline coordinate\nshots['distance'] = np.sqrt((shots['x_start'] - goal_center[0])**2 + (shots['y_start'] - goal_center[1])**2)\nshots['distance'] = shots['distance'].round(decimals = 2)\n\nNext, I calculate the angle of a shot. The task breaks down to finding the angle between two sides of a triangle given that all lengths (a, b, c) of the triangle are known.\nBelow you can see my implementation:\n\n# Angle Feature calculation\n\n# transform (x, y) coordinates from percentiles to field length coordinates (105 meters x 68 meters)\nx = shots['x_start'] * 105/120\ny = shots['y_start'] * 68/80 \n\n# Use trigonometric formula to find an angle between two sides (a,b) of a triangle where the third side (c) \n# is a goal line of length 7.32 meters.\na = np.sqrt((x - 105)**2 + (y - 30.34)**2) # length between right post and (x, y) shot coordinate\nb = np.sqrt((x - 105)**2 + (y - 37.66)**2) # length between left post and (x, y) shot coordinate\nc = 7.32 # goal line length in meters\ncos_alpha = (a**2 + b**2 - c**2)/(2*a*b)\ncos_alpha = np.round(cos_alpha, decimals = 4)\n\n# remember to leave angle in radians (if you want to transfer to degree multiply cos_alpha by 180/pi)\nshots['angle'] = np.arccos(cos_alpha)\n\nNow, I would like to demonstrate how both of these features impact the probability of scoring.\nI run a simple logistic regression that includes only these features (distance, angle) and obtain probabilisitc predictions for each shot. Then, I plot both of these features against the probabilistic predictions to visualize the relationship. The objective is to illustrate the relationship between the features and the probability of scoring.\n\n\nCode\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\n\n# Prepare features and labels from available data\nX = shots.loc[:, ['distance', 'angle']]\ny = shots.loc[:, 'outcome']\n\n# Fit Logistic Regression Model\nclassifier = LogisticRegression()\nclassifier.fit(X, y)\n\n# make predictions\npredictions = classifier.predict_proba(X)[:, 1]\n\n\n# Canvas\nfig, ax = plt.subplots(nrows = 1, ncols = 2, figsize = (10, 4))\n\n# Distance plot design\n\n# grid\nax[0].grid(color = 'black', ls = '-.', lw = 0.25, axis = \"both\")\n\n# plot\nax[0].scatter(X['distance'], predictions, color = 'gray', s = 0.5, alpha = 0.4)\nax[0].set_xlabel('Distance')\nax[0].set_ylabel('Probability of scoring')\n\n# axis adjustments\nax[0].set_ylim(0, 0.8)\nax[0].set_xlim(0, 90)\nax[0].yaxis.get_major_ticks()[0].label1.set_visible(False)\nax[0].tick_params(length = 0)\n\n############################################\n\n# Angle plot design\n\n# grid\nax[1].grid(color = 'black', ls = '-.', lw = 0.25, axis = \"both\")\n\n# plot\nax[1].scatter(X['angle'], predictions, color = 'orange', s = 0.5, alpha = 0.4)\nax[1].set_xlabel('Angle')\nax[1].set_ylabel('Probability of scoring')\n\n# axis adjustments\nax[1].set_ylim(0, 0.8)\nax[1].set_xlim(0, 3.5)\nax[1].yaxis.get_major_ticks()[0].label1.set_visible(False)\nax[1].tick_params(length = 0)\n\nax[0].text(x = 44, y = -0.2, s = 'a)', fontsize = 12)\nax[1].text(x = 1.72, y = -0.2, s = 'b)', fontsize = 12)\n\n\nplt.show()\n\n\n\n\n\nFigure 4: Probability of scoring decreases with increasing distance (a) and increases with increasing angle (b).\n\n\n\n\nAs can be seen from a) part of Figure 4, the inprobability of scoring (or you can also call it xG value) decreases exponentially with increasing distance. On the contrast, the probability of scoring increases linearly with angle.\nIn both plots of Figure 4, there are densely populated parts that can be analyzed in a slightly different way. From these areas a majority of shots is executed. When analyzing Figure 5, we can observe that most of the shots are executed within the distance range from 5 to 30 m. Most of the angles of the executed shots are distributed within the angle range from 0 to 60 degrees (or from 0 to 1 radians, respectively).\n\n\nCode\n# Canvas\nfig, ax = plt.subplots(nrows = 1, ncols = 2, figsize = (10, 4))\n\n# Distance density plot design\nax[0].grid(color = 'black', ls = '-.', lw = 0.25, axis = \"both\")\nsns.kdeplot(x = 'distance', data = shots, ax = ax[0], color = 'gray')\nax[0].set_xlabel('Distance')\nax[0].set_ylim(0, 0.045)\nax[0].set_yticks(np.arange(0, 0.045, 0.01))\nax[0].set_xlim(-10, 100)\n\n\n# Angle density plot design\nax[1].grid(color = 'black', ls = '-.', lw = 0.25, axis = \"both\")\nsns.kdeplot(x = 'angle', data = shots, ax = ax[1], color = 'orange')\nax[1].set_xlabel('Angle')\nax[1].set_ylim(0, 2.8)\n\nax[0].text(x = 44, y = -0.01, s = 'a)', fontsize = 12)\nax[1].text(x = 1.5, y = -0.63, s = 'b)', fontsize = 12)\n\n\nplt.show()\n\n\n\n\n\nFigure 5: Distribution of distances (a) and angles (b) for all executed shots."
  },
  {
    "objectID": "building_model.html#statistical-analysis",
    "href": "building_model.html#statistical-analysis",
    "title": "Part 2 | Building Model",
    "section": "Statistical Analysis",
    "text": "Statistical Analysis\nAll features are included into the logistic regression model to analyze their statistical signficance. The objective is to analyze p-values for each of the features and determine which of these values are weakly associated with the response.\n\n\nCode\n# Data Preparation\nX = shots.loc[:, ['play_pattern_name','under_pressure', 'distance', 'angle', 'gk_loc_x', 'gk_loc_y',\n                   'follows_dribble', 'first_time', 'open_goal', 'technique', 'body_part']]\ny = shots.loc[:, 'outcome']\n\ndf_train = pd.concat([X, y], axis = 1).reset_index(drop = True)\n\nimport statsmodels.formula.api as smf\n\n# run model\nlogreg_model = smf.logit(\n    formula = \"outcome ~ distance + angle + under_pressure + gk_loc_y + gk_loc_x + \\\n    body_part + open_goal + play_pattern_name\",\n                         data = df_train).fit()\n\n# Extract p-values\npd.DataFrame(logreg_model.pvalues, columns = ['p-value']).round(decimals = 3)\n\n\nOptimization terminated successfully.\n         Current function value: 0.284721\n         Iterations 8\n\n\n\n\n\n\n  \n    \n      \n      p-value\n    \n  \n  \n    \n      Intercept\n      0.000\n    \n    \n      body_part[T.Left Foot]\n      0.000\n    \n    \n      body_part[T.Other]\n      0.642\n    \n    \n      body_part[T.Right Foot]\n      0.000\n    \n    \n      play_pattern_name[T.From Counter]\n      0.001\n    \n    \n      play_pattern_name[T.From Free Kick]\n      0.000\n    \n    \n      play_pattern_name[T.From Goal Kick]\n      0.000\n    \n    \n      play_pattern_name[T.From Keeper]\n      0.203\n    \n    \n      play_pattern_name[T.From Kick Off]\n      0.239\n    \n    \n      play_pattern_name[T.From Throw In]\n      0.001\n    \n    \n      play_pattern_name[T.Other]\n      0.252\n    \n    \n      play_pattern_name[T.Regular Play]\n      0.000\n    \n    \n      distance\n      0.000\n    \n    \n      angle\n      0.000\n    \n    \n      under_pressure\n      0.056\n    \n    \n      gk_loc_y\n      0.431\n    \n    \n      gk_loc_x\n      0.000\n    \n    \n      open_goal\n      0.000\n    \n  \n\n\n\n\nThere are several categorical variables with very high p-values. These are body_part[T.Other], play_pattern_name[T.From Keeper], play_pattern_name[T.From Kick Off], play_pattern_name[T.Other] and gk_loc_y. Let us analyze these features and decide if we can drop them from the model.\nFirst, play_pattern_name column describes different types of play during which a shot was executed. Below code snippet shows that there are 9 types of play in total.\n\n\nCode\nshots.loc[:, 'play_pattern_name'].unique()\n\n\narray(['Regular Play', 'From Free Kick', 'From Throw In', 'From Counter',\n       'From Corner', 'From Keeper', 'From Goal Kick', 'From Kick Off',\n       'Other'], dtype=object)\n\n\n\n\nCode\n# Data preparation for barplot 1\nplay_types = pd.DataFrame(shots.loc[:, 'play_pattern_name'].value_counts()).reset_index()\nplay_types.columns = ['play_pattern_name', 'n']\nplay_types = play_types.sort_values(by = 'n', ascending = True)\n\n# Data preparation for barplot 2\nbody_part = pd.DataFrame(shots.loc[:, 'body_part'].value_counts()).reset_index()\nbody_part.columns = ['body_part', 'n']\nbody_part = body_part.sort_values(by = 'n', ascending = True)\n\n# Canvas\nfig, ax = plt.subplots(nrows = 1, ncols = 2, figsize = (4, 4))\n\n# Grid specs\nax[0].grid(color = 'black', ls = '-.', lw = 0.25, axis = \"x\")\n\n# Main plot\npl = ax[0].barh(play_types[\"play_pattern_name\"], play_types[\"n\"], height = 0.6, label = 'n',\n       color = 'skyblue', edgecolor = \"black\", zorder = 2, alpha = 0.7) \n\n# Barplot labels\nax[0].bar_label(pl, padding = 5, label_type='edge', fontsize = 8)\n\n# Labels and titles\nax[0].set_ylabel(\"Type of Play\", fontsize = 10)\nax[0].set_xlabel(\"# of instances\", fontsize = 10)\nax[0].tick_params(axis = 'both', which = 'major', labelsize = 8)\nax[0].spines[['top', 'right']].set_visible(False)\n\n#############################################################################\n\n# Grid specs\nax[1].grid(color = 'black', ls = '-.', lw = 0.25, axis = \"x\")\n\n# Main plot\npl2 = ax[1].barh(body_part[\"body_part\"], body_part[\"n\"], height = 0.4, label = 'n',\n       color = 'red', edgecolor = \"black\", zorder = 2, alpha = 0.7) \n\n# Barplot labels\nax[1].bar_label(pl2, padding = 5, label_type='edge', fontsize = 8)\n\n# Labels and titles\nax[1].set_ylabel(\"Body part\", fontsize = 10)\nax[1].set_xlabel(\"# of instances\", fontsize = 10)\nax[1].tick_params(axis = 'both', which = 'major', labelsize = 8)\nax[1].spines[['top', 'right']].set_visible(False)\n\n\n# Set the spacing parameters between subplots\nplt.subplots_adjust(left = 0.1,\n                    bottom = 1.3, \n                    right = 2, \n                    top = 2, \n                    wspace = 0.65, \n                    hspace = 0.5)\n\nplt.show()\n\n\n\n\n\nFigure 6: Distribution of shots in different types of play (left) and implemented with different parts of the body (right).\n\n\n\n\nFeatures play_pattern_name[T.From Keeper], play_pattern_name[T.From Kick Off], play_pattern_name[T.Other] that received high p-values are actually very rare events and can be considered as outliers in the model. There are very few situations in which attack starting from goalkeeper or from a kick-off can result in a goal. From Figure 6, it can be seen that, in total, 300 shots were executed in types of play: ‘From Keeper’, ‘From Kick Off’ and ‘Other’.\n\n\nCode\nprint(np.sum(shots.loc[shots['play_pattern_name'] == 'From Keeper', 'outcome']), \n     'goals were scored when attack was initiated by a goalkeeper.',)\n\n\n13 goals were scored when attack was initiated by a goalkeeper.\n\n\n\n\nCode\nprint(np.sum(shots.loc[shots['play_pattern_name'] == 'From Kick Off', 'outcome']),\n      'goals were scored when attack was initiated from a kick-off.')\n\n\n10 goals were scored when attack was initiated from a kick-off.\n\n\n\n\nCode\nprint(np.sum(shots.loc[shots['play_pattern_name'] == 'Other', 'outcome']),\n      'goals were scored when attack was initiated in other scenarios.')\n\n\n7 goals were scored when attack was initiated in other scenarios.\n\n\nIn total, only 30 out of these 300 shots were scored.\nA similar pattern can be observed when analyzing body_part categorical column and body_part[T.Other] feature that received a high p-value. Out of 11043 shots available in the dataset, only 30 shots were executed with a body part other than foot or head.\n\n\nCode\nprint('Only', np.sum(shots.loc[shots['body_part'] == 'Other', 'outcome']),\n      'goals out of 30 shots were scored with a body part other than foot or head.')\n\n\nOnly 6 goals out of 30 shots were scored with a body part other than foot or head.\n\n\nTo sum up both of these scenarios, only 330 shots and 36 goals fall into these outlying conditions. This is a relatively small sample size in comparison to the available data; thus, I exclude these data points from analysis.\n\n\nCode\nshots = shots.loc[~((shots['play_pattern_name'] == 'Other') | (shots['play_pattern_name'] == 'From Keeper' ) \n| (shots['play_pattern_name'] == 'From Kick Off') | (shots['body_part'] == 'Other')),  :]\n\n\nFinally, there is one more column gk_loc_y which also has a high p-value. This column together with gk_loc_x describe the location of the opposing team’s goalkeeper during an executed shot. Naturally, a goalkeeper standing on the goalline can move differently but in most of the cases along the goalline. This means that the y coordinate should change much more frequently than the x coordinate. However, the y coordinate is less significant in the model than the x coordinate. As of now, I will leave both of these features in the dataset."
  },
  {
    "objectID": "building_model.html#transforming-and-splitting-data",
    "href": "building_model.html#transforming-and-splitting-data",
    "title": "Part 2 | Building Model",
    "section": "Transforming and Splitting Data",
    "text": "Transforming and Splitting Data\nOne-hot encoding transformation is applied to all categorical variables present in the dataset. These are body_part, technique and play_pattern_name. Note that variables under_pressure, follows_dribble, first_time and open_goal are already transformed into 0/1 boolean variables (False/True); thus, they do not need any additional preprocessing. In addition, features distance, angle, gk_loc_x and gk_loc_y are standardized.\n\n\nCode\nfrom sklearn.model_selection import train_test_split\n# Prepare features and labels from available data\nX = shots.loc[:, ['play_pattern_name','under_pressure', 'distance', 'angle', 'gk_loc_x', 'gk_loc_y',\n                   'follows_dribble', 'first_time', 'open_goal', 'technique', 'body_part']]\ny = shots.loc[:, 'outcome']\n\n# split data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n\n\nIn the next section, model selection will be implemented using RandomizedSearchCV. Thus, the dataset is splitted into X_train, y_train, X_test, y_test where k-fold cross validation will be applied on X_train, y_train to find optimal parameters for each type of model. Finally, each model will be run on X_test, y_test to evaluate its performance on new data.\n\n\nCode\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\n\n# Build a column transformer\ncolumn_trans = ColumnTransformer(\n    [('encode_bodyparts', OneHotEncoder(dtype='int'), ['play_pattern_name', 'technique', 'body_part']),\n    ('std_coords', StandardScaler(), ['distance', 'angle', 'gk_loc_x', 'gk_loc_y'])],\n    remainder = 'passthrough', verbose_feature_names_out = True)\n\n# Transform feature columns\nX_train = column_trans.fit_transform(X_train)\nX_test = column_trans.transform(X_test)"
  },
  {
    "objectID": "building_model.html#model-selection",
    "href": "building_model.html#model-selection",
    "title": "Part 2 | Building Model",
    "section": "Model Selection",
    "text": "Model Selection\nThree different classifiers were run and evaluated on the given dataset. These are Logistic Regression, Gradient Boosting and Random Forest. Since I am interested in predicting probabilistic outputs, the aim is to achieve the highest accuracy of the probabilistic predictions. Thus, I use Brier score as an evaluation metric in RandomizedSearchCV. In addition, I evaluate ROC-AUC score for each model with its best parameters. However, ROC-AUC is mainly used here as a supportive metric to illustrate the performance in comparison with a random guess.\n\nLogistic Regression\n\n\nCode\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom scipy.stats import uniform\nfrom sklearn.metrics import roc_auc_score, brier_score_loss\n\n# Model\nmodel = LogisticRegression(solver = 'saga', max_iter = 200, random_state = 42)\n\n# Hyperparameters\nparameters = dict(C = uniform(loc = 0, scale = 4), \n                  penalty = ['l2', 'l1'])\n\n# Classifier\nclassifier = RandomizedSearchCV(model, parameters, random_state = 42, \n                                cv = 10, scoring = 'neg_brier_score')\nclassifier.fit(X_train, y_train)\nprint('Optimal parameters are:\\n', classifier.best_params_)\n\n# Evaluate on test data\npredictions = classifier.predict_proba(X_test)[:, 1]\nprint('Brier score = ', brier_score_loss(y_test, predictions))\nprint('ROC-AUC = ', roc_auc_score(y_test, predictions))\n\n\nOptimal parameters are:\n {'C': 1.49816047538945, 'penalty': 'l2'}\nBrier score =  0.0778472702630083\nROC-AUC =  0.7810976028573392\n\n\n\n\nGradient Boosting\n\n\nCode\nfrom sklearn.ensemble import GradientBoostingClassifier \nfrom scipy.stats import randint\n\n# Model\nmodel = GradientBoostingClassifier(random_state = 42)\n\n# Hyperparameters\nparameters = dict(learning_rate = uniform(loc = 0.03, scale = 0.035),\n                  n_estimators = randint(100, 800),\n                  loss = ['exponential', 'deviance'])\n# Classifier\nclassifier = RandomizedSearchCV(model, parameters, random_state = 42, \n                                cv = 10, scoring = 'neg_brier_score')\nclassifier.fit(X_train, y_train)\nprint('Optimal parameters are:\\n', classifier.best_params_)\n\n# Evaluate on test data\npredictions = classifier.predict_proba(X_test)[:, 1]\nprint('Brier score = ', brier_score_loss(y_test, predictions))\nprint('ROC-AUC = ', roc_auc_score(y_test, predictions))\n\n\nOptimal parameters are:\n {'learning_rate': 0.055619787963399184, 'loss': 'exponential', 'n_estimators': 120}\nBrier score =  0.07818749793751041\nROC-AUC =  0.7805726452954971\n\n\n\n\nRandom Forest\n\n\nCode\nfrom sklearn.ensemble import RandomForestClassifier\n\n# Model\nmodel = RandomForestClassifier(random_state = 42)\n\n# Hyperparameters\nparameters = dict(max_depth = randint(5, 50),\n                  criterion = ['entropy', 'gini'],\n                  min_samples_split = randint(2, 50))\n\n# Classifier\nclassifier = RandomizedSearchCV(model, parameters, random_state = 42, \n                                cv = 10, scoring = 'neg_brier_score')\nclassifier.fit(X_train, y_train)\nprint('Optimal parameters are:\\n', classifier.best_params_)\n\n# Evaluate on test data\npredictions = classifier.predict_proba(X_test)[:, 1]\nprint('Brier score = ', brier_score_loss(y_test, predictions))\nprint('ROC-AUC = ', roc_auc_score(y_test, predictions))\n\n\nOptimal parameters are:\n {'criterion': 'entropy', 'max_depth': 12, 'min_samples_split': 22}\nBrier score =  0.07892679615459904\nROC-AUC =  0.7761693797650938\n\n\nTo sum up, when comparing Brier scores for each classifier, it can be seen that Logistic Regression outperforms Gradient Boosting and Random Forest by a small margin. In addition, Logistic Regression demonstrates the highest ROC-AUC value (0.781). This value is well above 0.5, which confirms that the classifier performs much better than a random guess."
  },
  {
    "objectID": "building_model.html#future-improvements",
    "href": "building_model.html#future-improvements",
    "title": "Part 2 | Building Model",
    "section": "Future Improvements",
    "text": "Future Improvements\nThe model illustrates a good performance. However, there are always areas for improvement that I would like to briefly outline:\n\nPerform more thorough analysis of opposing team’s goalkeeper coordinates.\nAnalyze how discarded outliers may affect model performance.\nAnalyze the correlation between features using different techniques such as point biserial correlation and chi square test of association.\nUse the location of opposing team’s defenders to construct additional features."
  },
  {
    "objectID": "p1.html",
    "href": "p1.html",
    "title": "Expected Goals Model",
    "section": "",
    "text": "Soccer is a low-scoring game. Thus, it appears difficult to evaluate performance of teams by looking only at the number of scored and conceded goals. In comparison to goals, teams usually execute a much higher number of shots. However, not all of these shots are of the same quality. In other words, different shots may have different probabilities of being scored. These probabilities may depend on many different parameters. In this project, I implement Expected Goals Model that computes how likely is a given shot to result in a goal.\nProject repository is available here."
  },
  {
    "objectID": "p1.html#implementation",
    "href": "p1.html#implementation",
    "title": "Expected Goals Model",
    "section": "Implementation",
    "text": "Implementation\nThe project consists of the following parts:\n\nPart 1 | Data Preprocessing\nIn this section, I demonstrate how to extract data from an external resource, filter out only required competitions, specify the columns of interest and bring them into a desirable format.\nPart 2 | Building Model\nThis part mainly focuses on the exploratory data analysis, design of new features, statistical analysis of existing features, splitting and transforming data, hyperparameter tuning and model selection."
  },
  {
    "objectID": "data_preprocessing.html",
    "href": "data_preprocessing.html",
    "title": "Part 1 | Data Preprocessing",
    "section": "",
    "text": "In addition to pandas, the following packages need to be imported:\n\nimport os\nimport ast\nimport numpy as np \nimport pandas as pd\n\nThere are different publicly available soccer match event datasets. For this model, I decided to work with female soccer match event data due to a high granularity of event descriptions provided by the vendor, Statsbomb. This granularity can help me in building a sophisticated model and design features that can increase its accuracy. To learn more about other available datasets released by Statsbomb, feel free to visit this link.\nTo extract data from Statsbomb API, different methodologies are available. I prefer to work with socceraction library that allows me to extract data in a convenient pandas.DataFrame format.\n\n# import wyscout public match event data loader from socceraction library\nfrom socceraction.data.statsbomb import StatsBombLoader \n\n# remove credentials warning from statsbomb api since we work with public data \nimport warnings\nwarnings.filterwarnings(\"ignore\", message=\"credentials were not supplied. open data access only\")\n\n# load public wyscout data\nstbm_data = StatsBombLoader()\n\n# read available competitions and filter out only female related ones\ncompetitions = stbm_data.competitions()\nfemale_comps = competitions.loc[competitions['competition_gender'] == 'female', :].reset_index(drop = True)\nfemale_comps\n\n\n\n\n\n  \n    \n      \n      season_id\n      competition_id\n      competition_name\n      country_name\n      competition_gender\n      season_name\n    \n  \n  \n    \n      0\n      90\n      37\n      FA Women's Super League\n      England\n      female\n      2020/2021\n    \n    \n      1\n      42\n      37\n      FA Women's Super League\n      England\n      female\n      2019/2020\n    \n    \n      2\n      4\n      37\n      FA Women's Super League\n      England\n      female\n      2018/2019\n    \n    \n      3\n      3\n      49\n      NWSL\n      United States of America\n      female\n      2018\n    \n    \n      4\n      106\n      53\n      UEFA Women's Euro\n      Europe\n      female\n      2022\n    \n    \n      5\n      30\n      72\n      Women's World Cup\n      International\n      female\n      2019\n    \n  \n\n\n\n\nAs can be seen, data is available for four different female soccer competitions. Three seasons of FA Women’s Super League, one season of NWSL and two competitions involving national teams, UEFA Women’s Euro 2022 and Women’s World Cup 2019.\nBelow code illustrates steps required to read event data on each game from the aforementioned competitions and save it as .csv file. I also save all .csv files into a single all_events dataframe. Later, this will allow me to extract an event of interest from all games at once.\n\n# names of folders to save files\ndir_names = ['FAWSL_2021', 'FAWSL_1920', 'FAWSL_1819', 'NWSL', 'EURO_2022', 'WC_2019']\n\n# for each competition save all games as .csv files\nfor i, j in female_comps.loc[:, ['season_id', 'competition_id']].iterrows():\n    # j[0] = season_id, j[1] = competition_id\n    games = stbm_data.games(j[1], j[0]).loc[:, 'game_id']\n    for k in games:\n        events = stbm_data.events(k)\n        events.to_csv(f'.data/{dir_names[i]}/games/{k}.csv', index = False)\n\n# concatenate all events into a single data frame\nall_events = pd.DataFrame()\nfor i in dir_names:\n    games = os.listdir(f'.data/{i}/games')\n    for j in games:\n        df = pd.read_csv(f'.data/{i}/games/{j}')\n        all_events = pd.concat([all_events, df])\n\n# rest index and save as .csv file\nall_events = all_events.reset_index(drop = True)\nall_events.to_csv('.data/all_events.csv', index = False)\n\n\nall_events.head(3)\n\n\n\n\n\n  \n    \n      \n      game_id\n      event_id\n      period_id\n      team_id\n      player_id\n      type_id\n      type_name\n      index\n      timestamp\n      minute\n      ...\n      team_name\n      duration\n      extra\n      related_events\n      player_name\n      position_id\n      position_name\n      location\n      under_pressure\n      counterpress\n    \n  \n  \n    \n      0\n      3764230\n      3f5dde74-d91b-44ea-9a1f-88e84da555ab\n      1\n      749\n      NaN\n      35\n      Starting XI\n      1\n      1900-01-01 00:00:00.000\n      0\n      ...\n      Tottenham Hotspur Women\n      0.0\n      {'tactics': {'formation': 4231, 'lineup': [{'p...\n      []\n      NaN\n      NaN\n      NaN\n      NaN\n      False\n      False\n    \n    \n      1\n      3764230\n      e4fefe61-4e08-47e0-be4d-2276388e6eb4\n      1\n      972\n      NaN\n      35\n      Starting XI\n      2\n      1900-01-01 00:00:00.000\n      0\n      ...\n      West Ham United LFC\n      0.0\n      {'tactics': {'formation': 433, 'lineup': [{'pl...\n      []\n      NaN\n      NaN\n      NaN\n      NaN\n      False\n      False\n    \n    \n      2\n      3764230\n      ff9a99d3-3efd-45c2-8736-a8a93dd02638\n      1\n      972\n      NaN\n      18\n      Half Start\n      3\n      1900-01-01 00:00:00.000\n      0\n      ...\n      West Ham United LFC\n      0.0\n      {}\n      ['5fb7026c-83aa-4490-96b1-a55825c4dcb8']\n      NaN\n      NaN\n      NaN\n      NaN\n      False\n      False\n    \n  \n\n3 rows × 26 columns\n\n\n\nThere is a wide range of data describing each event. Since xG model evaluates the probability of a shot to result in a goal, I can filter only shot events, extract columns of interest to this event and test these columns after preprocessing in the model building phase.\n\n# list all features to select ones required for xG model\nall_events.columns\n\nIndex(['game_id', 'event_id', 'period_id', 'team_id', 'player_id', 'type_id',\n       'type_name', 'index', 'timestamp', 'minute', 'second', 'possession',\n       'possession_team_id', 'possession_team_name', 'play_pattern_id',\n       'play_pattern_name', 'team_name', 'duration', 'extra', 'related_events',\n       'player_name', 'position_id', 'position_name', 'location',\n       'under_pressure', 'counterpress'],\n      dtype='object')\n\n\n\n# filter event type_name = 'Shot' and leave only required columns \nshots = all_events.loc[all_events['type_name'] == 'Shot', \n                       ['minute', 'player_name', 'team_name', 'type_name', 'play_pattern_name', \n                        'position_name', 'location', 'under_pressure', 'extra']].reset_index(drop = True)\n\nThe following columns are dropped due to their irrelevance to the context of the model: ‘game_id’, ‘event_id’, ‘period_id’, ‘team_id’, ‘player_id’, ‘type_id’, ‘index’, ‘timestamp’, ‘minute’, ‘second’, ‘possession’, ‘possession_team_id’, ‘possession_team_name’, ‘play_pattern_id’, ‘duration’, ‘related_events’, ‘position_id’.\nAs you can see, a majority of these events are id identifiers. For example, play_pattern_id is ommited while play_pattern is left in the dataframe. The rest of the columns include time- or possession-related information which will not make any use in our case.\nOne of the most important columns, as we will see later, is location of the shot. I extract required (x, y) coordinates from a given list and save them as separate columns for a simpler use case during feature engineering phase.\nIt is important to note that when dataframes are saved as .csv files, all of them are converted into a raw string format. Thus, when reading these dataframes, one needs to convert columns containing specific datatypes into a python readable format. For that, I use ast package and, specifically, ast.literal_eval() function. This allows me to convert a string of a list into a python readable list object.\n\n# unlist location column into (x, y) and remove it\nshots.loc[:, 'location'] = shots.loc[:, 'location'].apply(ast.literal_eval)\nshots.loc[:, 'x_start'] = shots.loc[:, 'location'].apply(lambda x: x[0])\nshots.loc[:, 'y_start'] = shots.loc[:, 'location'].apply(lambda x: x[1])\nshots = shots.drop(columns = 'location')\n\n\nshots.head()\n\n\n\n\n\n  \n    \n      \n      minute\n      player_name\n      team_name\n      type_name\n      play_pattern_name\n      position_name\n      under_pressure\n      extra\n      x_start\n      y_start\n    \n  \n  \n    \n      0\n      7\n      Lucy Quinn\n      Tottenham Hotspur Women\n      Shot\n      Regular Play\n      Right Wing\n      False\n      {'shot': {'statsbomb_xg': 0.013642391, 'end_lo...\n      95.9\n      58.9\n    \n    \n      1\n      10\n      Rianna Dean\n      Tottenham Hotspur Women\n      Shot\n      From Free Kick\n      Center Forward\n      False\n      {'shot': {'statsbomb_xg': 0.04084396, 'end_loc...\n      106.1\n      54.3\n    \n    \n      2\n      11\n      Angela Addison\n      Tottenham Hotspur Women\n      Shot\n      From Free Kick\n      Left Wing\n      True\n      {'shot': {'statsbomb_xg': 0.13687119, 'end_loc...\n      110.0\n      28.2\n    \n    \n      3\n      13\n      Kit Graham\n      Tottenham Hotspur Women\n      Shot\n      From Throw In\n      Center Attacking Midfield\n      False\n      {'shot': {'statsbomb_xg': 0.12462413, 'end_loc...\n      113.2\n      40.4\n    \n    \n      4\n      16\n      Kit Graham\n      Tottenham Hotspur Women\n      Shot\n      From Counter\n      Center Attacking Midfield\n      False\n      {'shot': {'statsbomb_xg': 0.02380701, 'end_loc...\n      95.2\n      39.8\n    \n  \n\n\n\n\nThe column named extra contains additional information describing shot event. This is where we can observe that Statsbomb provides a high level of event data granularity. For example, below you can see that for each shot, the location of all players, specifically opposing team’s goalkeeper, within a visible video frame is recorded. In addition, there is data about body_part with which a shot was implemented, technique (which as per event data description guide is “name of the technique used for this shot”), open_goal which is a boolean variable that describes if a shot was taken with an open goal, follows_dribble which is a boolean variable that describes if a taken shot was followed by dribble or not and first_time which is a boolean variable that describes if a shot was taken with the first touch or not. Due to vendor specifications, only boolean variables with True state appear in extra column; thus, I have to specify False state for all other cases explicitly.\nAs you can see, variables follows_dribble and open_goal are missing from below instance of extra column due to False state.\n\nshots.loc[:, 'extra'][148]\n\n{'shot': {'open_goal': True,\n  'statsbomb_xg': 0.84770715,\n  'end_location': [120.0, 39.0, 0.9],\n  'body_part': {'id': 40, 'name': 'Right Foot'},\n  'type': {'id': 87, 'name': 'Open Play'},\n  'outcome': {'id': 97, 'name': 'Goal'},\n  'first_time': True,\n  'technique': {'id': 91, 'name': 'Half Volley'},\n  'freeze_frame': [{'location': [111.4, 38.3],\n    'player': {'id': 4647, 'name': 'So-Yun Ji'},\n    'position': {'id': 13, 'name': 'Right Center Midfield'},\n    'teammate': True},\n   {'location': [108.8, 42.9],\n    'player': {'id': 4636, 'name': 'Maria Thorisdottir'},\n    'position': {'id': 2, 'name': 'Right Back'},\n    'teammate': True},\n   {'location': [110.1, 53.6],\n    'player': {'id': 4961, 'name': 'Samantha May Kerr'},\n    'position': {'id': 21, 'name': 'Left Wing'},\n    'teammate': True},\n   {'location': [106.3, 51.4],\n    'player': {'id': 10108, 'name': 'Pernille Mosegaard Harder'},\n    'position': {'id': 17, 'name': 'Right Wing'},\n    'teammate': True},\n   {'location': [110.8, 35.7],\n    'player': {'id': 46738, 'name': 'Emma Bissell'},\n    'position': {'id': 16, 'name': 'Left Midfield'},\n    'teammate': False},\n   {'location': [110.1, 39.8],\n    'player': {'id': 36801, 'name': 'Aimee Palmer'},\n    'position': {'id': 13, 'name': 'Right Center Midfield'},\n    'teammate': False},\n   {'location': [116.1, 42.8],\n    'player': {'id': 16376, 'name': 'Sophie Baggaley'},\n    'position': {'id': 1, 'name': 'Goalkeeper'},\n    'teammate': False},\n   {'location': [116.1, 45.7],\n    'player': {'id': 16381, 'name': 'Gemma Evans'},\n    'position': {'id': 5, 'name': 'Left Center Back'},\n    'teammate': False},\n   {'location': [110.5, 46.1],\n    'player': {'id': 15618, 'name': 'Jasmine Matthews'},\n    'position': {'id': 3, 'name': 'Right Center Back'},\n    'teammate': False},\n   {'location': [111.2, 50.0],\n    'player': {'id': 24922, 'name': 'Florence Allen'},\n    'position': {'id': 2, 'name': 'Right Back'},\n    'teammate': False},\n   {'location': [114.5, 49.3],\n    'player': {'id': 24239, 'name': 'Jemma Elizabeth Purfield'},\n    'position': {'id': 6, 'name': 'Left Back'},\n    'teammate': False}]}}\n\n\nIn addition to above-mentioned data, I also extract contenxtual information from extra column. These are type, statsbomb_xg and outcome variables. The last one is important for knowing if a taken shot results in a goal or not. The variable type will help me to filter out only open play situations and discard outlying conditions where a shot is taken directly from corner, free-kick, penalty or kick-off. These are situations that can largely skew performance of the proposed xG model, and it is better to build a separate model that focuses only on them.\nI unpack extra column that consists of dictionaries, extract required data and save it as separate columns in the dataframe.\n\n# convert 'extra' column to dict readable format using ast.literal_eval\nshots_extra = shots.loc[:, 'extra'].apply(ast.literal_eval).reset_index(drop = True)\n\n# specify which features to extract from 'extra' column\nkeys = ['follows_dribble', 'first_time', 'open_goal', 'statsbomb_xg', \\\n        'type', 'technique', 'body_part', 'outcome']\n# save selected features in a dataframe\nextra_features = pd.DataFrame(np.nan, columns = keys, index = range(shots.shape[0]))\nfor i, j in shots_extra.iteritems():\n    for k in list(j['shot'].keys()):\n        if k in ['type', 'technique', 'body_part', 'outcome']:\n            extra_features.loc[i, k] = j['shot'][k]['name']\n        elif k in keys:\n            extra_features.loc[i, k] = j['shot'][k]\n        elif k == 'freeze_frame':\n            extra_features.loc[i, k] = [{'freeze_frame':j['shot'][k]}]\n        elif (k == 'end_location'):\n            extra_features.loc[i, 'end_loc'] = [{'end_loc':j['shot'][k]}]\n            \n        \n# fill NAs with boolean = False (technically, these are not NAs but just undeclared False values)\nextra_features = extra_features.fillna(value = False)\n# transform columns with boolean values into integers \nextra_features.loc[:, ['follows_dribble', 'first_time', 'open_goal']] = \\\nextra_features.loc[:, ['follows_dribble', 'first_time', 'open_goal']].astype(int)\nshots.loc[:, 'under_pressure'] = shots.loc[:, 'under_pressure'].astype(int)\n\n\nshots = pd.concat([shots.drop(columns = ['extra', 'type_name']), extra_features], axis = 1)\nshots.head()\n\n\n\n\n\n  \n    \n      \n      minute\n      player_name\n      team_name\n      play_pattern_name\n      position_name\n      under_pressure\n      x_start\n      y_start\n      follows_dribble\n      first_time\n      open_goal\n      statsbomb_xg\n      type\n      technique\n      body_part\n      outcome\n      end_loc\n      freeze_frame\n    \n  \n  \n    \n      0\n      7\n      Lucy Quinn\n      Tottenham Hotspur Women\n      Regular Play\n      Right Wing\n      0\n      95.9\n      58.9\n      0\n      0\n      0\n      0.013642\n      Open Play\n      Normal\n      Left Foot\n      Saved\n      [{'end_loc': [116.7, 44.9, 1.2]}]\n      [{'freeze_frame': [{'location': [119.6, 42.3],...\n    \n    \n      1\n      10\n      Rianna Dean\n      Tottenham Hotspur Women\n      From Free Kick\n      Center Forward\n      0\n      106.1\n      54.3\n      0\n      0\n      0\n      0.040844\n      Open Play\n      Normal\n      Right Foot\n      Off T\n      [{'end_loc': [120.0, 41.6, 4.2]}]\n      [{'freeze_frame': [{'location': [118.8, 43.2],...\n    \n    \n      2\n      11\n      Angela Addison\n      Tottenham Hotspur Women\n      From Free Kick\n      Left Wing\n      1\n      110.0\n      28.2\n      0\n      0\n      0\n      0.136871\n      Open Play\n      Normal\n      Left Foot\n      Saved\n      [{'end_loc': [117.6, 36.7, 0.4]}]\n      [{'freeze_frame': [{'location': [111.3, 39.8],...\n    \n    \n      3\n      13\n      Kit Graham\n      Tottenham Hotspur Women\n      From Throw In\n      Center Attacking Midfield\n      0\n      113.2\n      40.4\n      0\n      0\n      0\n      0.124624\n      Open Play\n      Normal\n      Head\n      Post\n      [{'end_loc': [120.0, 37.9, 2.9]}]\n      [{'freeze_frame': [{'location': [105.8, 46.6],...\n    \n    \n      4\n      16\n      Kit Graham\n      Tottenham Hotspur Women\n      From Counter\n      Center Attacking Midfield\n      0\n      95.2\n      39.8\n      0\n      0\n      0\n      0.023807\n      Open Play\n      Normal\n      Left Foot\n      Post\n      [{'end_loc': [120.0, 37.3, 2.9]}]\n      [{'freeze_frame': [{'location': [97.8, 49.4], ...\n    \n  \n\n\n\n\nAlso, I would like to extract opposing team’s goalkeeper location during each executed shot. These coordinates are contained in freeze_frame column.\n\n# write a custom function to unpack dictionaries within freeze_frame column\ndef ff_unpacking(players):\n    players = players[0]['freeze_frame']\n    for i in players:\n        if i['position']['name'] == 'Goalkeeper' and i['teammate'] == False:\n            gk_loc = i['location']\n            return gk_loc\n\nshots.loc[:, 'gk_loc'] = shots.loc[:, 'freeze_frame'].apply(lambda x: ff_unpacking(x))\n\n# Note that there are 42 None instances where goalkeeper location was incorrectly labeled.\nshots = shots.loc[~shots.loc[:, 'gk_loc'].isnull(), :].reset_index(drop = True)\n\n# save (x, y) coordinates of a goalkeeper as separate columns\nshots.loc[:, 'gk_loc_x'] = shots.loc[:, 'gk_loc'].apply(lambda x: x[0])\nshots.loc[:, 'gk_loc_y'] = shots.loc[:, 'gk_loc'].apply(lambda x: x[1])\n\nFinally, I save my shots dataframe as .csv file.\n\nshots.to_csv('.data/shots.csv', index = False)\n\nThis is the end of preprocessing stage for data that will be used in the proposed xG model. Now, we can move on to the model building phase that will focus on exploratory data analysis, feature engineering and model selection."
  },
  {
    "objectID": "posts/first-post/index.html",
    "href": "posts/first-post/index.html",
    "title": "First Post",
    "section": "",
    "text": "To learn more about Quarto websites visit https://quarto.org/docs/websites. I would like to tell my story but where should I start ? This is important for me to understand how to communicate several problems ?"
  },
  {
    "objectID": "posts/second-post/index.html",
    "href": "posts/second-post/index.html",
    "title": "Second Post",
    "section": "",
    "text": "To learn more about Quarto websites visit https://quarto.org/docs/websites. I would like to tell my story but where should I start ? This is important for me to understand how to communicate several problems ?"
  }
]